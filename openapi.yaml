openapi: 3.1.0
info:
  title: Together APIs
  description: The Together REST API. Please see https://docs.together.ai for more details.
  version: '2.0.0'
  termsOfService: https://www.together.ai/terms-of-service
  contact:
    name: Together Support
    url: https://www.together.ai/contact
  license:
    name: MIT
    url: https://github.com/togethercomputer/openapi/blob/main/LICENSE
servers:
  - url: https://api.together.xyz/v1
security:
  - bearerAuth: []
paths:
  /chat/completions:
    post:
      tags: ['Chat']
      summary: Create chat completion
      description: Query a chat model.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.chat.completions.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "What are some fun things to do in New York?"},
                ]
            )

            print(response.choices[0].message.content)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.chat.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", "content": "What are some fun things to do in New York?" },
              ],
            });

            console.log(response.choices[0].message?.content);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.chat.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              messages: [
                { role: "system", content: "You are a helpful assistant." },
                { role: "user", "content": "What are some fun things to do in New York?" },
              ],
            });

            console.log(response.choices[0].message?.content);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/chat/completions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "messages": [
                     {"role": "system", "content": "You are a helpful assistant."},
                     {"role": "user", "content": "What are some fun things to do in New York?"}
                   ]
                 }'
      operationId: chat-completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ChatCompletionRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ChatCompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/ChatCompletionStream'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'NotFound'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: 'Overloaded'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: 'Timeout'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      deprecated: false
  /completions:
    post:
      tags: ['Completion']
      summary: Create completion
      description: Query a language, code, or image model.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.completions.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                prompt="The largest city in France is",
                max_tokens=1
            )

            print(response.choices[0].text)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              prompt: "The largest city in France is",
              max_tokens: 1
            });

            console.log(response.choices[0].text);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.completions.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              prompt: "The largest city in France is",
              max_tokens: 1
            });

            console.log(response.choices[0].text);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/completions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "prompt": "The largest city in France is",
                   "max_tokens": 1
                 }'
      operationId: completions
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CompletionRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CompletionResponse'
            text/event-stream:
              schema:
                $ref: '#/components/schemas/CompletionStream'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'NotFound'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: 'Overloaded'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: 'Timeout'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      deprecated: false
  /embeddings:
    post:
      tags: ['Embeddings']
      summary: Create embedding
      description: Query an embedding model for a given string of text.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.embeddings.create(
                model="BAAI/bge-large-en-v1.5",
                input="New York City",
            )

            print(response.data[0].embedding)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.embeddings.create({
              model: "BAAI/bge-large-en-v1.5",
              input: "New York City",
            });

            console.log(response.data[0].embedding);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.embeddings.create({
              model: "BAAI/bge-large-en-v1.5",
              input: "New York City",
            });

            console.log(response.data[0].embedding);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/embeddings" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "BAAI/bge-large-en-v1.5",
                   "input": "New York City"
                 }'
      operationId: embeddings
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EmbeddingsRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EmbeddingsResponse'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'NotFound'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: 'Overloaded'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: 'Timeout'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      deprecated: false
  /models:
    get:
      tags: ['Models']
      summary: List all models
      description: Lists all of Together's open-source models
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            models = client.models.list()

            for model in models:
                print(model.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const models = await client.models.list();

            for (const model of models) {
              console.log(model.id);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const models = await client.models.list();

            for (const model of models) {
              console.log(model.id);
            }
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/models" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      operationId: models
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelInfoList'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'NotFound'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: 'Timeout'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      deprecated: false
    post:
      tags: ['Models']
      summary: Upload a custom model or adapter
      description: Upload a custom model or adapter from Hugging Face or S3
      x-codeSamples:
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.models.upload({
              model_name: "My-Fine-Tuned-Model",
              model_source: "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz",
            })

            console.log(response);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.models.upload({
              model_name: "My-Fine-Tuned-Model",
              model_source: "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz",
            })

            console.log(response);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/models" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                    "model_name": "My-Fine-Tuned-Model",
                    "model_source": "https://ml-models.s3.us-west-2.amazonaws.com/models/my-fine-tuned-model.tar.gz"
                  }'
      operationId: uploadModel
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModelUploadRequest'
      responses:
        '200':
          description: Model / adapter upload job created successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelUploadSuccessResponse'

  /jobs/{jobId}:
    get:
      tags: ['Jobs']
      summary: Get job status
      description: Get the status of a specific job
      operationId: getJob
      parameters:
        - name: jobId
          in: path
          required: true
          schema:
            type: string
          description: The ID of the job to retrieve
          example: job-a15dad11-8d8e-4007-97c5-a211304de284
      responses:
        '200':
          description: Job status retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/JobInfoSuccessResponse'

  /jobs:
    get:
      tags: ['Jobs']
      summary: List all jobs
      description: List all jobs and their statuses
      operationId: listJobs
      responses:
        '200':
          description: Jobs retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/JobsInfoSuccessResponse'

  /images/generations:
    post:
      tags: ['Images']
      summary: Create image
      description: Use an image model to generate an image for a given prompt.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.images.generate(
                model="black-forest-labs/FLUX.1-schnell",
                steps=4,
                prompt="A cartoon of an astronaut riding a horse on the moon",
            )

            print(response.data[0].url)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.images.create({
              model: "black-forest-labs/FLUX.1-schnell",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.data[0].url);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.images.create({
              model: "black-forest-labs/FLUX.1-schnell",
              prompt: "A cartoon of an astronaut riding a horse on the moon",
            });

            console.log(response.data[0].url);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/images/generations" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "black-forest-labs/FLUX.1-schnell",
                   "prompt": "A cartoon of an astronaut riding a horse on the moon"
                 }'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - prompt
                - model
              properties:
                prompt:
                  type: string
                  description: A description of the desired images. Maximum length varies by model.
                  example: cat floating in space, cinematic
                model:
                  type: string
                  description: >
                    The model to use for image generation.<br>
                    <br>
                    [See all of Together AI's image models](https://docs.together.ai/docs/serverless-models#image-models)
                  example: black-forest-labs/FLUX.1-schnell
                  anyOf:
                    - type: string
                      enum:
                        - black-forest-labs/FLUX.1-schnell-Free
                        - black-forest-labs/FLUX.1-schnell
                        - black-forest-labs/FLUX.1.1-pro
                    - type: string
                steps:
                  type: integer
                  default: 20
                  description: Number of generation steps.
                image_url:
                  type: string
                  description: URL of an image to use for image models that support it.
                seed:
                  type: integer
                  description: Seed used for generation. Can be used to reproduce image generations.
                n:
                  type: integer
                  default: 1
                  description: Number of image results to generate.
                height:
                  type: integer
                  default: 1024
                  description: Height of the image to generate in number of pixels.
                width:
                  type: integer
                  default: 1024
                  description: Width of the image to generate in number of pixels.
                negative_prompt:
                  type: string
                  description: The prompt or prompts not to guide the image generation.
                response_format:
                  type: string
                  description: Format of the image response. Can be either a base64 string or a URL.
                  enum:
                    - base64
                    - url
                guidance_scale:
                  type: number
                  description: Adjusts the alignment of the generated image with the input prompt. Higher values (e.g., 8-10) make the output more faithful to the prompt, while lower values (e.g., 1-5) encourage more creative freedom.
                  default: 3.5
                output_format:
                  type: string
                  description: The format of the image response. Can be either be `jpeg` or `png`. Defaults to `jpeg`.
                  default: jpeg
                  enum:
                    - jpeg
                    - png
                image_loras:
                  description: An array of objects that define LoRAs (Low-Rank Adaptations) to influence the generated image.
                  type: array
                  items:
                    type: object
                    required: [path, scale]
                    properties:
                      path:
                        type: string
                        description: The URL of the LoRA to apply (e.g. https://huggingface.co/strangerzonehf/Flux-Midjourney-Mix2-LoRA).
                      scale:
                        type: number
                        description: The strength of the LoRA's influence. Most LoRA's recommend a value of 1.
                disable_safety_checker:
                  type: boolean
                  description: If true, disables the safety checker for image generation.
      responses:
        '200':
          description: Image generated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ImageResponse'
  /files:
    get:
      tags: ['Files']
      summary: List all files
      description: List the metadata for all uploaded data files.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.list()

            for file in response.data:
                print(file.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.list();

            for (const file of response.data) {
              console.log(file.id);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.list();

            for (const file of response.data) {
              console.log(file.id);
            }
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/files" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      responses:
        '200':
          description: List of files
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileList'
  /files/{id}:
    get:
      tags: ['Files']
      summary: List file
      description: List the metadata for a single uploaded data file.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = client.files.retrieve(id="file-id")

            print(file)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const file = await client.files.retrieve("file-id");

            console.log(file);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const file = await client.files.retrieve("file-id");

            console.log(file);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/files/ID" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'
    delete:
      tags: ['Files']
      summary: Delete a file
      description: Delete a previously uploaded data file.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.files.delete(id="file-id")

            print(response)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.delete("file-id");

            console.log(response);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.delete("file-id");

            console.log(response);
        - lang: Shell
          label: cURL
          source: |
            curl -X "DELETE" "https://api.together.xyz/v1/files/file-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File deleted successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileDeleteResponse'
  /files/{id}/content:
    get:
      tags: ['Files']
      summary: Get file contents
      description: Get the contents of a single uploaded data file.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = client.files.retrieve_content(id="file-id")

            print(file.filename)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.content("file-id");
            const content = await response.text();

            console.log(content);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.files.content("file-id");
            const content = await response.text();

            console.log(content);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/files/file-id/content" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: File content retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileObject'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /files/upload:
    post:
      tags: ['Files']
      summary: Upload a file
      description: Upload a file with specified purpose, file name, and file type.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            current_dir = os.path.dirname(os.path.abspath(__file__))
            file_path = os.path.join(current_dir, "data.jsonl")
            file = client.files.upload(file=file_path)

            print(file.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import { upload } from "together-ai/lib/upload"
            import path from "path";
            import { fileURLToPath } from "url";

            const __filename = fileURLToPath(import.meta.url);
            const __dirname = path.dirname(__filename);
            const filepath = path.join(__dirname, "data.jsonl");
            const file = await upload(filepath);

            console.log(file.id);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import { upload } from "together-ai/lib/upload"
            import path from "path";
            import { fileURLToPath } from "url";

            const __filename = fileURLToPath(import.meta.url);
            const __dirname = path.dirname(__filename);
            const filepath = path.join(__dirname, "data.jsonl");
            const file = await upload(filepath);

            console.log(file.id);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/files/upload" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@/path/to/data.jsonl" \
                 -F "file_name=data.jsonl" \
                 -F "purpose=fine-tune"
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              type: object
              required:
                - purpose
                - file_name
                - file
              properties:
                purpose:
                  $ref: '#/components/schemas/FilePurpose'
                file_name:
                  type: string
                  description: The name of the file being uploaded
                  example: 'dataset.csv'
                file_type:
                  $ref: '#/components/schemas/FileType'
                file:
                  type: string
                  format: binary
                  description: The content of the file being uploaded
      responses:
        '200':
          description: File uploaded successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FileResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /fine-tunes:
    post:
      tags: ['Fine-tuning']
      summary: Create job
      description: Create a fine-tuning job with the provided model and training data.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
                training_file="file-id"
            )

            print(response)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
              training_file: "file-id",
            });

            console.log(response);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
              training_file: "file-id",
            });

            console.log(response);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/fine-tunes" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Reference",
                   "training_file": "file-id"
                 }'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - training_file
                - model
              properties:
                training_file:
                  type: string
                  description: File-ID of a training file uploaded to the Together API
                validation_file:
                  type: string
                  description: File-ID of a validation file uploaded to the Together API
                model:
                  type: string
                  description: Name of the base model to run fine-tune job on
                n_epochs:
                  type: integer
                  default: 1
                  description: Number of complete passes through the training dataset (higher values may improve results but increase cost and risk of overfitting)
                n_checkpoints:
                  type: integer
                  default: 1
                  description: Number of intermediate model versions saved during training for evaluation
                n_evals:
                  type: integer
                  default: 0
                  description: Number of evaluations to be run on a given validation set during training
                batch_size:
                  oneOf:
                    - type: integer
                    - type: string
                      enum:
                        - max
                  default: 'max'
                  description: Number of training examples processed together (larger batches use more memory but may train faster). Defaults to "max". We use training optimizations like packing, so the effective batch size may be different than the value you set.
                learning_rate:
                  type: number
                  format: float
                  default: 0.00001
                  description: Controls how quickly the model adapts to new information (too high may cause instability, too low may slow convergence)
                lr_scheduler:
                  type: object
                  default: none
                  $ref: '#/components/schemas/LRScheduler'
                  description: The learning rate scheduler to use. It specifies how the learning rate is adjusted during training.
                warmup_ratio:
                  type: number
                  format: float
                  default: 0.0
                  description: The percent of steps at the start of training to linearly increase the learning rate.
                max_grad_norm:
                  type: number
                  format: float
                  default: 1.0
                  description: Max gradient norm to be used for gradient clipping. Set to 0 to disable.
                weight_decay:
                  type: number
                  format: float
                  default: 0.0
                  description: Weight decay. Regularization parameter for the optimizer.
                suffix:
                  type: string
                  description: Suffix that will be added to your fine-tuned model name
                wandb_api_key:
                  type: string
                  description: Integration key for tracking experiments and model metrics on W&B platform
                wandb_base_url:
                  type: string
                  description: The base URL of a dedicated Weights & Biases instance.
                wandb_project_name:
                  type: string
                  description: The Weights & Biases project for your run. If not specified, will use `together` as the project name.
                wandb_name:
                  type: string
                  description: The Weights & Biases name for your run.
                train_on_inputs:
                  oneOf:
                    - type: boolean
                    - type: string
                      enum:
                        - auto
                  type: boolean
                  default: auto
                  description: Whether to mask the user messages in conversational data or prompts in instruction data.
                  deprecated: true
                training_method:
                  type: object
                  oneOf:
                    - $ref: '#/components/schemas/TrainingMethodSFT'
                    - $ref: '#/components/schemas/TrainingMethodDPO'
                  description: The training method to use. 'sft' for Supervised Fine-Tuning or 'dpo' for Direct Preference Optimization.
                training_type:
                  type: object
                  oneOf:
                    - $ref: '#/components/schemas/FullTrainingType'
                    - $ref: '#/components/schemas/LoRATrainingType'
                from_checkpoint:
                  type: string
                  description: The checkpoint identifier to continue training from a previous fine-tuning job. Format is `{$JOB_ID}` or `{$OUTPUT_MODEL_NAME}` or `{$JOB_ID}:{$STEP}` or `{$OUTPUT_MODEL_NAME}:{$STEP}`. The step value is optional; without it, the final checkpoint will be used.
                from_hf_model:
                  type: string
                  description: The Hugging Face Hub repo to start training from. Should be as close as possible to the base model (specified by the `model` argument) in terms of architecture and size.
                hf_model_revision:
                  type: string
                  description: The revision of the Hugging Face Hub model to continue training from. E.g., hf_model_revision=main (default, used if the argument is not provided) or hf_model_revision='607a30d783dfa663caf39e06633721c8d4cfcd7e' (specific commit).
                hf_api_token:
                  type: string
                  description: The API token for the Hugging Face Hub.
                hf_output_repo_name:
                  type: string
                  description: The name of the Hugging Face repository to upload the fine-tuned model to.
      responses:
        '200':
          description: Fine-tuning job initiated successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponseTruncated'
    get:
      tags: ['Fine-tuning']
      summary: List all jobs
      description: List the metadata for all fine-tuning jobs. Returns a list of FinetuneResponseTruncated objects.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.list()

            for fine_tune in response.data:
                print(f"ID: {fine_tune.id}, Status: {fine_tune.status}")
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.list();

            for (const fineTune of response.data) {
              console.log(fineTune.id, fineTune.status);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.list();

            for (const fineTune of response.data) {
              console.log(fineTune.id, fineTune.status);
            }
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/fine-tunes" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      responses:
        '200':
          description: List of fine-tune jobs
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneTruncatedList'
  /fine-tunes/{id}:
    get:
      tags: ['Fine-tuning']
      summary: List job
      description: List the metadata for a single fine-tuning job.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            fine_tune = client.fine_tuning.retrieve(id="ft-id")

            print(fine_tune)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const fineTune = await client.fineTune.retrieve("ft-id");

            console.log(fineTune);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const fineTune = await client.fineTune.retrieve("ft-id");

            console.log(fineTune);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: Fine-tune job details retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponse'
  /fine-tunes/{id}/events:
    get:
      tags: ['Fine-tuning']
      summary: List job events
      description: List the events for a single fine-tuning job.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            events = client.fine_tuning.list_events(id="ft-id")

            print(events)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const events = await client.fineTune.listEvents("ft-id");

            console.log(events);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const events = await client.fineTune.listEvents("ft-id");

            console.log(events);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id/events" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: List of fine-tune events
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneListEvents'
  /fine-tunes/{id}/checkpoints:
    get:
      tags: ['Fine-tuning']
      summary: List checkpoints
      description: List the checkpoints for a single fine-tuning job.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            checkpoints = client.fine_tuning.list_checkpoints(id="ft-id")

            print(checkpoints)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const checkpoints = await client.fineTune.retrieveCheckpoints("ft-id");

            console.log(checkpoints);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const checkpoints = await client.fineTune.retrieveCheckpoints("ft-id");

            console.log(checkpoints);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/fine-tunes/ft-id/checkpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - name: id
          in: path
          required: true
          schema:
            type: string
      responses:
        '200':
          description: List of fine-tune checkpoints
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneListCheckpoints'
  /finetune/download:
    get:
      tags: ['Fine-tuning']
      summary: Download model
      description: Download a compressed fine-tuned model or checkpoint to local disk.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.download(id="ft-id")

            print(response)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.download({
              ft_id: "ft-id",
              checkpoint: "merged",
            });

            console.log(response);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.download({
              ft_id: "ft-id",
              checkpoint: "merged",
            });

            console.log(response);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/finetune/download?ft_id=ft-id&checkpoint=merged"
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - in: query
          name: ft_id
          schema:
            type: string
          required: true
          description: Fine-tune ID to download. A string that starts with `ft-`.
        - in: query
          name: checkpoint_step
          schema:
            type: integer
          required: false
          description: Specifies step number for checkpoint to download. Ignores `checkpoint` value if set.
        - in: query
          name: checkpoint
          schema:
            type: string
            enum:
              - merged
              - adapter
          description: Specifies checkpoint type to download - `merged` vs `adapter`. This field is required if the checkpoint_step is not set.
        - in: query
          name: output
          schema:
            type: string
          required: false
          description: Specifies output file name for downloaded model. Defaults to `$PWD/{model_name}.{extension}`.
      responses:
        '200':
          description: Successfully downloaded the fine-tuned model or checkpoint.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneDownloadResult'
        '400':
          description: Invalid request parameters.
        '404':
          description: Fine-tune ID not found.
  /fine-tunes/{id}/cancel:
    post:
      tags: ['Fine-tuning']
      summary: Cancel job
      description: Cancel a currently running fine-tuning job. Returns a FinetuneResponseTruncated object.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.fine_tuning.cancel(id="ft-id")

            print(response)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.cancel("ft-id");

            console.log(response);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.fineTune.cancel("ft-id");

            console.log(response);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/fine-tunes/ft-id/cancel" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      parameters:
        - in: path
          name: id
          schema:
            type: string
          required: true
          description: Fine-tune ID to cancel. A string that starts with `ft-`.
      responses:
        '200':
          description: Successfully cancelled the fine-tuning job.
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FinetuneResponseTruncated'
        '400':
          description: Invalid request parameters.
        '404':
          description: Fine-tune ID not found.
  /rerank:
    post:
      tags: ['Rerank']
      summary: Create a rerank request
      description: Query a reranker model
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            documents = [
                {
                    "title": "Llama",
                    "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
                },
                {
                    "title": "Panda",
                    "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
                },
                {
                    "title": "Guanaco",
                    "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
                },
                {
                    "title": "Wild Bactrian camel",
                    "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
                }
            ]

            response = client.rerank.create(
                model="Salesforce/Llama-Rank-v1",
                query="What animals can I find near Peru?",
                documents=documents,
            )

            for result in response.results:
                print(f"Rank: {result.index + 1}")
                print(f"Title: {documents[result.index]['title']}")
                print(f"Text: {documents[result.index]['text']}")
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const documents = [{
              "title": "Llama",
              "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
            },
            {
              "title": "Panda",
              "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
            },
            {
              "title": "Guanaco",
              "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
            },
            {
              "title": "Wild Bactrian camel",
              "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
            }];

            const response = await client.rerank({
              model: "Salesforce/Llama-Rank-v1",
              query: "What animals can I find near Peru?",
              documents,
            });

            for (const result of response.results) {
              console.log(`Rank: ${result.index + 1}`);
              console.log(`Title: ${documents[result.index].title}`);
              console.log(`Text: ${documents[result.index].text}`);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const documents = [{
              "title": "Llama",
              "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
            },
            {
              "title": "Panda",
              "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
            },
            {
              "title": "Guanaco",
              "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
            },
            {
              "title": "Wild Bactrian camel",
              "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
            }];

            const response = await client.rerank({
              model: "Salesforce/Llama-Rank-v1",
              query: "What animals can I find near Peru?",
              documents,
            });

            for (const result of response.results) {
              console.log(`Rank: ${result.index + 1}`);
              console.log(`Title: ${documents[result.index].title}`);
              console.log(`Text: ${documents[result.index].text}`);
            }
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/rerank" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "Salesforce/Llama-Rank-v1",
                   "query": "What animals can I find near Peru?",
                   "documents": [{
                      "title": "Llama",
                      "text": "The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."
                    },
                    {
                      "title": "Panda",
                      "text": "The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China."
                    },
                    {
                      "title": "Guanaco",
                      "text": "The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."
                    },
                    {
                      "title": "Wild Bactrian camel",
                      "text": "The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia."
                    }]
                 }'
      operationId: rerank
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/RerankRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/RerankResponse'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'NotFound'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '503':
          description: 'Overloaded'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '504':
          description: 'Timeout'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
      deprecated: false
  /audio/speech:
    post:
      tags: ['Audio']
      summary: Create audio generation request
      description: Generate audio from input text
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.audio.speech.create(
                model="cartesia/sonic-2",
                input="The quick brown fox jumps over the lazy dog.",
                voice="laidback woman",
            )

            response.stream_to_file("audio.wav")
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";
            import { createWriteStream } from "fs";
            import { join } from "path";
            import { pipeline } from "stream/promises";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.audio.create({
              model: "cartesia/sonic-2",
              input: "The quick brown fox jumps over the lazy dog.",
              voice: "laidback woman",
            });

            const filepath = join(process.cwd(), "audio.wav");
            const writeStream = createWriteStream(filepath);

            if (response.body) {
              await pipeline(response.body, writeStream);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";
            import { createWriteStream } from "fs";
            import { join } from "path";
            import { pipeline } from "stream/promises";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.audio.create({
              model: "cartesia/sonic-2",
              input: "The quick brown fox jumps over the lazy dog.",
              voice: "laidback woman",
            });

            const filepath = join(process.cwd(), "audio.wav");
            const writeStream = createWriteStream(filepath);

            if (response.body) {
              await pipeline(response.body, writeStream);
            }
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/speech" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "cartesia/sonic-2",
                   "input": "The quick brown fox jumps over the lazy dog.",
                   "voice": "laidback woman"
                 }' \
                 --output audio.wav
      operationId: audio-speech
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/AudioSpeechRequest'
      responses:
        '200':
          description: 'OK'
          content:
            application/octet-stream:
              schema:
                type: string
                format: binary
            audio/wav:
              schema:
                type: string
                format: binary
            audio/mpeg:
              schema:
                type: string
                format: binary
            text/event-stream:
              schema:
                $ref: '#/components/schemas/AudioSpeechStreamResponse'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /audio/transcriptions:
    post:
      tags: ['Audio']
      summary: Create audio transcription request
      description: Transcribes audio into text
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = open("audio.wav", "rb")

            response = client.audio.transcriptions.create(
                model="openai/whisper-large-v3",
                file=file,
            )

            print(response.text)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.transcriptions.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
            });

            console.log(response.text);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.transcriptions.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
            });

            console.log(response.text);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/transcriptions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@audio.wav" \
                 -F "model=openai/whisper-large-v3"
      operationId: audio-transcriptions
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranscriptionRequest'
      responses:
        '200':
          description: 'OK'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranscriptionResponse'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /audio/translations:
    post:
      tags: ['Audio']
      summary: Create audio translation request
      description: Translates audio into English
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            file = open("audio.wav", "rb")

            response = client.audio.translations.create(
                model="openai/whisper-large-v3",
                file=file,
                language="es",
            )

            print(response.text)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.translations.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
              language: "es"
            });

            console.log(response.text);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";
            import { readFileSync } from "fs";
            import { join } from "path";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const audioFilePath = join(process.cwd(), "audio.wav");
            const audioBuffer = readFileSync(audioFilePath);
            const audioFile = new File([audioBuffer], "audio.wav", { type: "audio/wav" });

            const response = await client.audio.translations.create({
              model: "openai/whisper-large-v3",
              file: audioFile,
              language: "es"
            });

            console.log(response.text);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/audio/transcriptions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -F "file=@audio.wav" \
                 -F "model=openai/whisper-large-v3" \
                 -F "language=es"
      operationId: audio-translations
      requestBody:
        required: true
        content:
          multipart/form-data:
            schema:
              $ref: '#/components/schemas/AudioTranslationRequest'
      responses:
        '200':
          description: 'OK'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AudioTranslationResponse'
        '400':
          description: 'BadRequest'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '401':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '429':
          description: 'RateLimit'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /endpoints:
    get:
      tags: ['Endpoints']
      summary: List all endpoints, can be filtered by type
      description: Returns a list of all endpoints associated with your account. You can filter the results by type (dedicated or serverless).
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoints = client.endpoints.list()

            for endpoint in endpoints:
                print(endpoint.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoints = await client.endpoints.list();

            for (const endpoint of endpoints.data) {
              console.log(endpoint);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoints = await client.endpoints.list();

            for (const endpoint of endpoints.data) {
              console.log(endpoint);
            }
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/endpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      operationId: listEndpoints
      parameters:
        - name: type
          in: query
          required: false
          schema:
            type: string
            enum:
              - dedicated
              - serverless
          description: Filter endpoints by type
          example: dedicated
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                type: object
                required:
                  - object
                  - data
                properties:
                  object:
                    type: string
                    enum:
                      - list
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/ListEndpoint'
                example:
                  object: 'list'
                  data:
                    - object: 'endpoint'
                      id: 'endpoint-5c0c20db-62fe-4f41-8ffc-d9e4ea1a264e'
                      name: 'allenai/OLMo-7B'
                      model: 'allenai/OLMo-7B'
                      type: 'serverless'
                      owner: 'together'
                      state: 'STARTED'
                      created_at: '2024-02-28T21:34:35.444Z'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
    post:
      tags: ['Endpoints']
      summary: Create a dedicated endpoint, it will start automatically
      description: Creates a new dedicated endpoint for serving models. The endpoint will automatically start after creation. You can deploy any supported model on hardware configurations that meet the model's requirements.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.create(
                model="meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                hardware="1x_nvidia_a100_80gb_sxm",
                min_replicas=2,
                max_replicas=5,
            )

            print(endpoint.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              hardware: "1x_nvidia_a100_80gb_sxm",
              autoscaling: {
                max_replicas: 5,
                min_replicas: 2,
              }
            });

            console.log(endpoint.id);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.create({
              model: "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
              hardware: "1x_nvidia_a100_80gb_sxm",
              autoscaling: {
                max_replicas: 5,
                min_replicas: 2,
              }
            });

            console.log(endpoint.id);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/endpoints" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "model": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                   "hardware": "1x_nvidia_a100_80gb_sxm",
                   "autoscaling": {
                     "max_replicas": 5,
                     "min_replicas": 2
                   }
                 }'
      operationId: createEndpoint
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateEndpointRequest'
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /endpoints/{endpointId}:
    get:
      tags: ['Endpoints']
      summary: Get endpoint by ID
      description: Retrieves details about a specific endpoint, including its current state, configuration, and scaling settings.
      x-codeSamples:
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.retrieve("endpoint-id");

            console.log(endpoint);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.retrieve("endpoint-id");

            console.log(endpoint);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      operationId: getEndpoint
      parameters:
        - name: endpointId
          in: path
          required: true
          schema:
            type: string
          description: The ID of the endpoint to retrieve
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'Not Found'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

    patch:
      tags: ['Endpoints']
      summary: Update endpoint, this can also be used to start or stop a dedicated endpoint
      description: Updates an existing endpoint's configuration. You can modify the display name, autoscaling settings, or change the endpoint's state (start/stop).
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.update(
                endpoint_id="endpoint-id",
                state="STOPPED"
            )

            print(endpoint)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.update("endpoint-id", {
              state: "STOPPED"
            });

            console.log(endpoint);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.update("endpoint-id", {
              state: "STOPPED"
            });

            console.log(endpoint);
        - lang: Shell
          label: cURL
          source: |
            curl -X PATCH "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "state": "STOPPED"
                 }'
      operationId: updateEndpoint
      parameters:
        - name: endpointId
          in: path
          required: true
          schema:
            type: string
          description: The ID of the endpoint to update
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                display_name:
                  type: string
                  description: A human-readable name for the endpoint
                  example: My Llama3 70b endpoint
                state:
                  type: string
                  description: The desired state of the endpoint
                  enum:
                    - STARTED
                    - STOPPED
                  example: STARTED
                autoscaling:
                  $ref: '#/components/schemas/Autoscaling'
                  description: New autoscaling configuration for the endpoint
                inactive_timeout:
                  type: integer
                  description: The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to 0 to disable automatic timeout.
                  nullable: true
                  example: 60
      responses:
        '200':
          description: '200'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/DedicatedEndpoint'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'Not Found'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

    delete:
      tags: ['Endpoints']
      summary: Delete endpoint
      description: Permanently deletes an endpoint. This action cannot be undone.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            endpoint = client.endpoints.delete(
                endpoint_id="endpoint-id",
            )

            print(endpoint)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.delete("endpoint-id");

            console.log(endpoint);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const endpoint = await client.endpoints.delete("endpoint-id");

            console.log(endpoint);
        - lang: Shell
          label: cURL
          source: |
            curl -X "DELETE" "https://api.together.xyz/v1/endpoints/endpoint-id" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY"
      operationId: deleteEndpoint
      parameters:
        - name: endpointId
          in: path
          required: true
          schema:
            type: string
          description: The ID of the endpoint to delete
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
      responses:
        '204':
          description: 'No Content - Endpoint successfully deleted'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: 'Not Found'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /hardware:
    get:
      tags: ['Hardware']
      summary: List available hardware configurations
      description: >
        Returns a list of available hardware configurations for deploying models.
        When a model parameter is provided, it returns only hardware configurations compatible
        with that model, including their current availability status.
      x-codeSamples:
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const hardware = await client.hardware.list();

            console.log(hardware);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const hardware = await client.hardware.list();

            console.log(hardware);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/hardware" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      operationId: listHardware
      parameters:
        - name: model
          in: query
          required: false
          schema:
            type: string
          description: >
            Filter hardware configurations by model compatibility. When provided,
            the response includes availability status for each compatible configuration.
          example: meta-llama/Llama-3-70b-chat-hf
      responses:
        '200':
          description: 'List of available hardware configurations'
          content:
            application/json:
              schema:
                type: object
                required:
                  - object
                  - data
                properties:
                  object:
                    type: string
                    enum:
                      - list
                  data:
                    type: array
                    items:
                      $ref: '#/components/schemas/HardwareWithStatus'
        '403':
          description: 'Unauthorized'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: 'Internal error'
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
  /tci/execute:
    post:
      tags: ['Code Interpreter']
      callbacks: {}
      description: |
        Executes the given code snippet and returns the output. Without a session_id, a new session will be created to run the code. If you do pass in a valid session_id, the code will be run in that session. This is useful for running multiple code snippets in the same environment, because dependencies and similar things are persisted
        between calls to the same session.
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            response = client.code_interpreter.run(
                code="print('Hello world!')",
                language="python",
            )

            print(response.data.outputs[0].data);
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.execute({
              code: "print('Hello world!')",
              language: "python"
            });

            console.log(response.data?.outputs?.[0]?.data);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.execute({
              code: "print('Hello world!')",
              language: "python"
            });

            console.log(response.data?.outputs?.[0]?.data);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/tci/execute" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "code": "print(\'Hello world!\')",
                   "language": "python"
                 }'
      operationId: tci/execute
      parameters: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ExecuteRequest'
        description: Execute Request
        required: false
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ExecuteResponse'
          description: Execute Response
  /tci/sessions:
    get:
      tags: ['Code Interpreter']
      callbacks: {}
      description: |
        Lists all your currently active sessions.
      x-codeSamples:
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.sessions.list();

            for (const session of response.data?.sessions) {
              console.log(session.id);
            }
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const response = await client.codeInterpreter.sessions.list();

            for (const session of response.data?.sessions) {
              console.log(session.id);
            }
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/tci/sessions" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      operationId: sessions/list
      parameters: []
      responses:
        '200':
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/SessionListResponse'
          description: List Response
  /batches:
    get:
      tags: ['Batches']
      summary: List batch jobs
      description: List all batch jobs for the authenticated user
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batches = client.batches.list_batches()

            for batch in batches:
                print(batch.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batches = await client.batches.list();

            console.log(batches);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batches = await client.batches.list();

            console.log(batches);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/batches" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      security:
        - bearerAuth: []
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/BatchJob'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
    post:
      tags: ['Batches']
      summary: Create a batch job
      description: Create a new batch job with the given input file and endpoint
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batch = client.batches.create_batch("file_id", endpoint="/v1/chat/completions")

            print(batch.id)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.create({
              endpoint: "/v1/chat/completions",
              input_file_id: "file-id",
            });

            console.log(batch);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.create({
              endpoint: "/v1/chat/completions",
              input_file_id: "file-id",
            });

            console.log(batch);
        - lang: Shell
          label: cURL
          source: |
            curl -X POST "https://api.together.xyz/v1/batches" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json" \
                 -d '{
                   "endpoint": "/v1/chat/completions",
                   "input_file_id": "file-id"
                 }'
      security:
        - bearerAuth: []
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CreateBatchRequest'
      responses:
        '201':
          description: Job created (potentially with warnings)
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchJobWithWarning'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '429':
          description: Too Many Requests
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'

  /batches/{id}:
    get:
      tags: ['Batches']
      summary: Get a batch job
      description: Get details of a batch job by ID
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            batch = client.batches.get_batch("batch_id")

            print(batch)
        - lang: TypeScript
          label: Together AI SDK (TypeScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.retrieve("batch-id");

            console.log(batch);
        - lang: JavaScript
          label: Together AI SDK (JavaScript)
          source: |
            import Together from "together-ai";

            const client = new Together({
              apiKey: process.env.TOGETHER_API_KEY,
            });

            const batch = await client.batches.retrieve("batch-id");

            console.log(batch);
        - lang: Shell
          label: cURL
          source: |
            curl "https://api.together.xyz/v1/batches/ID" \
                 -H "Authorization: Bearer $TOGETHER_API_KEY" \
                 -H "Content-Type: application/json"
      security:
        - bearerAuth: []
      parameters:
        - name: id
          in: path
          required: true
          description: Job ID
          schema:
            type: string
          example: 'batch_job_abc123def456'
      responses:
        '200':
          description: OK
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchJob'
        '400':
          description: Bad Request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '401':
          description: Unauthorized
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '403':
          description: Forbidden
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '404':
          description: Not Found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'
        '500':
          description: Internal Server Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/BatchErrorResponse'

  /evaluation:
    post:
      tags: ['Evaluations']
      summary: Create a new evaluation job
      description: Creates a new evaluation job for classify, score, or compare tasks
      operationId: evaluation-create
      x-codeSamples:
        - lang: Python
          label: Together AI SDK (Python)
          source: |
            from together import Together
            import os

            client = Together(
                api_key=os.environ.get("TOGETHER_API_KEY"),
            )

            client.evaluation.create(
                type="classify",
                judge_model_name="meta-llama/Llama-3.2-3B-Instruct-Turbo",
                judge_system_template="You are a helpful assistant which can classify",
                input_data_file_path="file-1234-5678-abcd",
                labels=["Toxic", "Non-Toxic"],
                pass_labels=["Toxic"],
                model_to_evaluate={
                    "name": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
                    "system_template": "You are a helpful assistant which can classify",
                    "input_template": "please classify '{{prompt}}' into one of these two categories",
                    "max_tokens": 512,
                    "temperature": 0.7
                }
            )
        - lang: Shell
          label: cURL
          source: |
            curl --location 'https://api.together.xyz/v1/evaluation' \
            --header 'Content-Type: application/json' \
            --header "Authorization: Bearer $TOGETHER_API_KEY" \
            --data '{
                "type": "classify",
                "parameters": {
                    "judge": {
                        "model_name": "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
                        "system_template": "You are an expert at identifying toxic content. Your task is to determine whether the answer contains toxic, rude, disrespectful, or harmful language."
                    },
                    "labels": ["Toxic", "Non-toxic"],
                    "pass_labels": ["Non-toxic"],
                    "model_to_evaluate": {
                        "model_name": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
                        "system_template": "Respond to the following comment. You can be informal but maintain a respectful tone.",
                        "input_template": "Here'\''s a comment I saw online. How would you respond to it?\n\n{{prompt}}",
                        "max_tokens": 512,
                        "temperature": 0.7
                    },
                    "input_data_file_path": "file-dccb332d-4365-451c-a9db-873813a1ba52"
                }
            }'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/EvaluationTypedRequest'
            examples:
              classify:
                summary: Classify evaluation example
                value:
                  type: classify
                  parameters:
                    judge:
                      model_name: 'meta-llama/Llama-3-70B-Instruct-Turbo'
                      system_template: 'You are a helpful assistant that classifies text.'
                    labels: ['Toxic', 'Non-Toxic']
                    pass_labels: ['Non-Toxic']
                    model_to_evaluate: 'output_column'
                    input_data_file_path: 'file-abcd-1234'
              score:
                summary: Score evaluation example
                value:
                  type: score
                  parameters:
                    judge:
                      model_name: 'meta-llama/Llama-3-70B-Instruct-Turbo'
                      system_template: 'You are a helpful assistant that scores responses.'
                    min_score: 0
                    max_score: 10
                    pass_threshold: 7
                    model_to_evaluate:
                      model_name: 'meta-llama/Llama-3-8B-Instruct-Turbo'
                      max_tokens: 512
                      temperature: 0.7
                      system_template: 'You are a helpful assistant.'
                      input_template: 'Classify: {prompt}'
                    input_data_file_path: 'file-1234-abcd'
              compare:
                summary: Compare evaluation example
                value:
                  type: compare
                  parameters:
                    judge:
                      model_name: 'meta-llama/Llama-3-70B-Instruct-Turbo'
                      system_template: 'You are a helpful assistant that compares responses.'
                    model_a: 'response_a'
                    model_b: 'response_b'
                    input_data_file_path: 'file-1234-abcd'
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvaluationResponse'
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: File not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /evaluations:
    get:
      tags: ['Evaluations']
      summary: List evaluation jobs
      description: Get a list of evaluation jobs with optional filtering
      operationId: evaluations-list
      parameters:
        - name: status
          in: query
          description: Filter by job status
          schema:
            type: string
            enum: [pending, queued, running, completed, error, user_error]
        - name: limit
          in: query
          description: Maximum number of results to return (max 100)
          schema:
            type: integer
            minimum: 1
            maximum: 100
            default: 10
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/EvaluationJob'
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /evaluation/{id}:
    get:
      tags: ['Evaluations']
      summary: Get evaluation job details
      description: Get details of a specific evaluation job
      operationId: evaluation-get
      parameters:
        - name: id
          in: path
          required: true
          description: The evaluation job ID
          schema:
            type: string
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/EvaluationJob'
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /evaluation/{id}/status:
    get:
      tags: ['Evaluations']
      summary: Get evaluation job status and results
      description: Get the status and results of a specific evaluation job
      operationId: evaluation-status
      parameters:
        - name: id
          in: path
          required: true
          description: The evaluation job ID
          schema:
            type: string
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    enum:
                      [pending, queued, running, completed, error, user_error]
                    example: completed
                  results:
                    oneOf:
                      - $ref: '#/components/schemas/EvaluationClassifyResults'
                      - $ref: '#/components/schemas/EvaluationScoreResults'
                      - $ref: '#/components/schemas/EvaluationCompareResults'
                      - type: object
                        properties:
                          error:
                            type: string
                    nullable: true
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /evaluation/{id}/update:
    post:
      tags: ['Evaluations']
      summary: Update evaluation job status
      description: Internal callback endpoint for workflows to update job status and results
      operationId: evaluation-update
      parameters:
        - name: id
          in: path
          required: true
          description: The evaluation job ID
          schema:
            type: string
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              required:
                - status
              properties:
                status:
                  type: string
                  enum:
                    [
                      completed,
                      error,
                      running,
                      queued,
                      user_error,
                      inference_error,
                    ]
                  description: The new status for the job
                results:
                  type: object
                  description: Job results (required when status is 'completed')
                error:
                  type: string
                  description: Error message
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  workflow_id:
                    type: string
                  status:
                    type: string
        '400':
          description: Bad request
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '404':
          description: Job not found
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

  /evaluations/model-list:
    get:
      tags: ['Evaluations']
      summary: Get allowed models list
      description: Get the list of models that are allowed for evaluation
      operationId: evaluations-model-list
      responses:
        '200':
          description: Successful response
          content:
            application/json:
              schema:
                type: object
                properties:
                  model_list:
                    type: array
                    items:
                      type: string
        '500':
          description: Internal server error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ErrorData'

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      x-bearer-format: bearer
      x-default: default

  schemas:
    RerankRequest:
      type: object
      properties:
        model:
          type: string
          description: >
            The model to be used for the rerank request.<br>
            <br>
            [See all of Together AI's rerank models](https://docs.together.ai/docs/serverless-models#rerank-models)
          example: Salesforce/Llama-Rank-V1
          anyOf:
            - type: string
              enum:
                - Salesforce/Llama-Rank-v1
            - type: string

        query:
          type: string
          description: The search query to be used for ranking.
          example: What animals can I find near Peru?
        documents:
          description: List of documents, which can be either strings or objects.
          oneOf:
            - type: array
              items:
                type: object
                additionalProperties: true
            - type: array
              items:
                type: string
                example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
          example:
            - {
                'title': 'Llama',
                'text': 'The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era.',
              }
            - {
                'title': 'Panda',
                'text': 'The giant panda (Ailuropoda melanoleuca), also known as the panda bear or simply panda, is a bear species endemic to China.',
              }
            - {
                'title': 'Guanaco',
                'text': 'The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations.',
              }
            - {
                'title': 'Wild Bactrian camel',
                'text': 'The wild Bactrian camel (Camelus ferus) is an endangered species of camel endemic to Northwest China and southwestern Mongolia.',
              }
        top_n:
          type: integer
          description: The number of top results to return.
          example: 2
        return_documents:
          type: boolean
          description: Whether to return supplied documents with the response.
          example: true
        rank_fields:
          type: array
          items:
            type: string
          description: List of keys in the JSON Object document to rank by. Defaults to use all supplied keys for ranking.
          example: ['title', 'text']
      required:
        - model
        - query
        - documents
      additionalProperties: false

    RerankResponse:
      type: object
      required:
        - object
        - model
        - results
      properties:
        object:
          type: string
          description: Object type
          enum:
            - rerank
          example: rerank
        id:
          type: string
          description: Request ID
          example: 9dfa1a09-5ebc-4a40-970f-586cb8f4ae47
        model:
          type: string
          description: The model to be used for the rerank request.
          example: salesforce/turboranker-0.8-3778-6328
        results:
          type: array
          items:
            type: object
            required: [index, relevance_score, document]
            properties:
              index:
                type: integer
              relevance_score:
                type: number
              document:
                type: object
                properties:
                  text:
                    type: string
                    nullable: true
          example:
            - {
                'index': 0,
                'relevance_score': 0.29980177813003117,
                'document':
                  {
                    'text': '{"title":"Llama","text":"The llama is a domesticated South American camelid, widely used as a meat and pack animal by Andean cultures since the pre-Columbian era."}',
                  },
              }
            - {
                'index': 2,
                'relevance_score': 0.2752447527354349,
                'document':
                  {
                    'text': '{"title":"Guanaco","text":"The guanaco is a camelid native to South America, closely related to the llama. Guanacos are one of two wild South American camelids; the other species is the vicuña, which lives at higher elevations."}',
                  },
              }
        usage:
          $ref: '#/components/schemas/UsageData'
          example:
            {
              'prompt_tokens': 1837,
              'completion_tokens': 0,
              'total_tokens': 1837,
            }

    ErrorData:
      type: object
      required:
        - error
      properties:
        error:
          type: object
          properties:
            message:
              type: string
              nullable: false
            type:
              type: string
              nullable: false
            param:
              type: string
              nullable: true
              default: null
            code:
              type: string
              nullable: true
              default: null
          required:
            - type
            - message

    FinishReason:
      type: string
      enum:
        - stop
        - eos
        - length
        - tool_calls
        - function_call

    LogprobsPart:
      type: object
      properties:
        token_ids:
          type: array
          items:
            type: number
          description: List of token IDs corresponding to the logprobs
        tokens:
          type: array
          items:
            type: string
          description: List of token strings
        token_logprobs:
          type: array
          items:
            type: number
          description: List of token log probabilities

    PromptPart:
      type: array
      items:
        type: object
        properties:
          text:
            type: string
            example: <s>[INST] What is the capital of France? [/INST]
          logprobs:
            $ref: '#/components/schemas/LogprobsPart'

    InferenceWarning:
      type: object
      required:
        - message
      properties:
        message:
          type: string

    UsageData:
      type: object
      properties:
        prompt_tokens:
          type: integer
        completion_tokens:
          type: integer
        total_tokens:
          type: integer
      required:
        - prompt_tokens
        - completion_tokens
        - total_tokens
      nullable: true

    CompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          text:
            type: string
            example: The capital of France is Paris. It's located in the north-central part of the country and is one of the most populous and visited cities in the world, known for its iconic landmarks like the Eiffel Tower, Louvre Museum, Notre-Dame Cathedral, and more. Paris is also the capital of the Île-de-France region and is a major global center for art, fashion, gastronomy, and culture.
          seed:
            type: integer
          finish_reason:
            $ref: '#/components/schemas/FinishReason'
          logprobs:
            $ref: '#/components/schemas/LogprobsPart'

    CompletionRequest:
      type: object
      required:
        - model
        - prompt
      properties:
        prompt:
          type: string
          description: A string providing context for the model to complete.
          example: <s>[INST] What is the capital of France? [/INST]
        model:
          type: string
          description: >
            The name of the model to query.<br>
            <br>
            [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
          anyOf:
            - type: string
              enum:
                - meta-llama/Llama-2-70b-hf
                - mistralai/Mistral-7B-v0.1
                - mistralai/Mixtral-8x7B-v0.1
                - Meta-Llama/Llama-Guard-7b
            - type: string
        max_tokens:
          type: integer
          description: The maximum number of tokens to generate.
        stop:
          type: array
          description: A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.
          items:
            type: string
        temperature:
          type: number
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
        top_p:
          type: number
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
        top_k:
          type: integer
          description: An integer that's used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.
          format: int32
        repetition_penalty:
          type: number
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
          format: float
        stream:
          type: boolean
          description: 'If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results.'
        logprobs:
          type: integer
          minimum: 0
          maximum: 20
          description: An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.
        echo:
          type: boolean
          description: If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.
        n:
          type: integer
          description: The number of completions to generate for each prompt.
          minimum: 1
          maximum: 128
        safety_model:
          type: string
          description: The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).
          example: 'safety_model_name'
          anyOf:
            - type: string
              enum:
                - Meta-Llama/Llama-Guard-7b
            - type: string
        min_p:
          type: number
          description: A number between 0 and 1 that can be used as an alternative to top-p and top-k.
          format: float
        presence_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
        frequency_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
        logit_bias:
          type: object
          additionalProperties:
            type: number
            format: float
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example: { '1024': -10.5, '105': 21.4 }
        seed:
          type: integer
          description: Seed value for reproducibility.
          example: 42
    CompletionResponse:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: '#/components/schemas/CompletionChoicesData'
        prompt:
          $ref: '#/components/schemas/PromptPart'
        usage:
          $ref: '#/components/schemas/UsageData'
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - text.completion
      required:
        - id
        - choices
        - usage
        - created
        - model
        - object

    CompletionStream:
      oneOf:
        - $ref: '#/components/schemas/CompletionEvent'
        - $ref: '#/components/schemas/StreamSentinel'

    CompletionEvent:
      type: object
      required: [data]
      properties:
        data:
          $ref: '#/components/schemas/CompletionChunk'

    CompletionChunk:
      type: object
      required: [id, token, choices, usage, finish_reason]
      properties:
        id:
          type: string
        token:
          $ref: '#/components/schemas/CompletionToken'
        created:
          type: integer
        object:
          type: string
          enum:
            - completion.chunk
        choices:
          title: CompletionChoices
          type: array
          items:
            $ref: '#/components/schemas/CompletionChoice'
        usage:
          allOf:
            - $ref: '#/components/schemas/UsageData'
            - nullable: true
        seed:
          type: integer
        finish_reason:
          allOf:
            - $ref: '#/components/schemas/FinishReason'
            - nullable: true

    CompletionChoice:
      type: object
      required: [index]
      properties:
        text:
          type: string
        index:
          type: integer
        delta:
          title: CompletionChoiceDelta
          type: object
          required: [role]
          properties:
            token_id:
              type: integer
            role:
              type: string
              enum: ['system', 'user', 'assistant', 'function', 'tool']
            content:
              type: string
              nullable: true
            tool_calls:
              type: array
              items:
                $ref: '#/components/schemas/ToolChoice'
            function_call:
              type: object
              deprecated: true
              nullable: true
              properties:
                arguments:
                  type: string
                name:
                  type: string
              required:
                - arguments
                - name

    CompletionToken:
      type: object
      required: [id, text, logprob, special]
      properties:
        id:
          type: integer
        text:
          type: string
        logprob:
          type: number
        special:
          type: boolean

    ChatCompletionChoicesData:
      type: array
      items:
        type: object
        properties:
          text:
            type: string
          index:
            type: integer
          seed:
            type: integer
          finish_reason:
            $ref: '#/components/schemas/FinishReason'
          message:
            $ref: '#/components/schemas/ChatCompletionMessage'
          logprobs:
            allOf:
              - nullable: true
              - $ref: '#/components/schemas/LogprobsPart'
    ChatCompletionMessage:
      type: object
      required: [role, content]
      properties:
        content:
          type: string
          nullable: true
        role:
          type: string
          enum: [assistant]
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolChoice'
        function_call:
          type: object
          deprecated: true
          required: [arguments, name]
          properties:
            arguments:
              type: string
            name:
              type: string
    ChatCompletionTool:
      type: object
      required: [type, function]
      properties:
        type:
          type: string
          enum: ['function']
        function:
          type: object
          required: [name]
          properties:
            description:
              type: string
            name:
              type: string
            parameters:
              type: object
              additionalProperties: true

    ChatCompletionRequest:
      type: object
      required:
        - model
        - messages
      properties:
        messages:
          type: array
          description: A list of messages comprising the conversation so far.
          items:
            $ref: '#/components/schemas/ChatCompletionMessageParam'
        model:
          description: >
            The name of the model to query.<br>
            <br>
            [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#chat-models)
          example: meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
          anyOf:
            - type: string
              enum:
                - Qwen/Qwen2.5-72B-Instruct-Turbo
                - Qwen/Qwen2.5-7B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo
                - meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo
            - type: string
        max_tokens:
          type: integer
          description: The maximum number of tokens to generate.
        stop:
          type: array
          description: A list of string sequences that will truncate (stop) inference text output. For example, "</s>" will stop generation as soon as the model generates the given token.
          items:
            type: string
        temperature:
          type: number
          description: A decimal number from 0-1 that determines the degree of randomness in the response. A temperature less than 1 favors more correctness and is appropriate for question answering or summarization. A value closer to 1 introduces more randomness in the output.
          format: float
        top_p:
          type: number
          description: A percentage (also called the nucleus parameter) that's used to dynamically adjust the number of choices for each predicted token based on the cumulative probabilities. It specifies a probability threshold below which all less likely tokens are filtered out. This technique helps maintain diversity and generate more fluent and natural-sounding text.
          format: float
        top_k:
          type: integer
          description: An integer that's used to limit the number of choices for the next predicted word or token. It specifies the maximum number of tokens to consider at each step, based on their probability of occurrence. This technique helps to speed up the generation process and can improve the quality of the generated text by focusing on the most likely options.
          format: int32
        context_length_exceeded_behavior:
          type: string
          enum: ['truncate', 'error']
          default: 'error'
          description: Defined the behavior of the API when max_tokens exceed the maximum context length of the model. When set to 'error', API will return 400 with appropriate error message. When set to 'truncate', override the max_tokens with maximum context length of the model.
        repetition_penalty:
          type: number
          description: A number that controls the diversity of generated text by reducing the likelihood of repeated sequences. Higher values decrease repetition.
        stream:
          type: boolean
          description: 'If true, stream tokens as Server-Sent Events as the model generates them instead of waiting for the full model response. The stream terminates with `data: [DONE]`. If false, return a single JSON object containing the results.'
        logprobs:
          type: integer
          minimum: 0
          maximum: 20
          description: An integer between 0 and 20 of the top k tokens to return log probabilities for at each generation step, instead of just the sampled token. Log probabilities help assess model confidence in token predictions.
        echo:
          type: boolean
          description: If true, the response will contain the prompt. Can be used with `logprobs` to return prompt logprobs.
        n:
          type: integer
          description: The number of completions to generate for each prompt.
          minimum: 1
          maximum: 128
        min_p:
          type: number
          description: A number between 0 and 1 that can be used as an alternative to top_p and top-k.
          format: float
        presence_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value increases the likelihood of a model talking about new topics.
          format: float
        frequency_penalty:
          type: number
          description: A number between -2.0 and 2.0 where a positive value decreases the likelihood of repeating tokens that have already been mentioned.
          format: float
        logit_bias:
          type: object
          additionalProperties:
            type: number
            format: float
          description: Adjusts the likelihood of specific tokens appearing in the generated output.
          example: { '1024': -10.5, '105': 21.4 }
        seed:
          type: integer
          description: Seed value for reproducibility.
          example: 42
        function_call:
          oneOf:
            - type: string
              enum: [none, auto]
            - type: object
              required: [name]
              properties:
                name:
                  type: string
        response_format:
          type: object
          description: An object specifying the format that the model must output.
          properties:
            type:
              description: The type of the response format.
              type: string
              example: json
            schema:
              description: The schema of the response format.
              type: object
              additionalProperties: true
        tools:
          type: array
          description: A list of tools the model may call. Currently, only functions are supported as a tool. Use this to provide a list of functions the model may generate JSON inputs for.
          items:
            $ref: '#/components/schemas/ToolsPart'
        tool_choice:
          description: Controls which (if any) function is called by the model. By default uses `auto`, which lets the model pick between generating a message or calling a function.
          oneOf:
            - type: string
              example: 'tool_name'
            - $ref: '#/components/schemas/ToolChoice'
        safety_model:
          type: string
          description: The name of the moderation model used to validate tokens. Choose from the available moderation models found [here](https://docs.together.ai/docs/inference-models#moderation-models).
          example: 'safety_model_name'
        reasoning_effort:
          type: string
          enum: ['low', 'medium', 'high']
          description: Controls the level of reasoning effort the model should apply when generating responses. Higher values may result in more thoughtful and detailed responses but may take longer to generate.
          example: 'medium'

    ChatCompletionMessageParam:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionSystemMessageParam'
        - $ref: '#/components/schemas/ChatCompletionUserMessageParam'
        - $ref: '#/components/schemas/ChatCompletionAssistantMessageParam'
        - $ref: '#/components/schemas/ChatCompletionToolMessageParam'
        - $ref: '#/components/schemas/ChatCompletionFunctionMessageParam'

    # Start Message Params

    ChatCompletionSystemMessageParam:
      type: object
      required: [content, role]
      properties:
        content:
          type: string
        role:
          type: string
          enum: ['system']
        name:
          type: string

    ChatCompletionUserMessageParam:
      type: object
      required: [content, role]
      properties:
        content:
          $ref: '#/components/schemas/ChatCompletionUserMessageContent'
        role:
          type: string
          enum: ['user']
        name:
          type: string

    ChatCompletionUserMessageContentString:
      type: string
      description: A plain text message.

    ChatCompletionUserMessageContentMultimodal:
      type: array
      description: A structured message with mixed content types.
      items:
        type: object
        oneOf:
          - type: object
            properties:
              type:
                type: string
                enum:
                  - text
              text:
                type: string
            required:
              - type
              - text
          - type: object
            properties:
              type:
                type: string
                enum:
                  - image_url
              image_url:
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the image
                required:
                  - url
          - type: object
            title: Video
            properties:
              type:
                type: string
                enum:
                  - video_url
              video_url:
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the video
                required:
                  - url
            required:
              - type
              - video_url
          - type: object
            title: Audio
            properties:
              type:
                type: string
                enum:
                  - audio_url
              audio_url:
                type: object
                properties:
                  url:
                    type: string
                    description: The URL of the audio
                required:
                  - url
            required:
              - type
              - audio_url
          - type: object
            title: Input Audio
            properties:
              type:
                type: string
                enum:
                  - input_audio
              input_audio:
                type: object
                properties:
                  data:
                    type: string
                    description: The base64 encoded audio data
                  format:
                    type: string
                    description: The format of the audio data
                    enum:
                      - wav
                required:
                  - data
                  - format
            required:
              - type
              - input_audio

    ChatCompletionUserMessageContent:
      description: The content of the message, which can either be a simple string or a structured format.
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionUserMessageContentString'
        - $ref: '#/components/schemas/ChatCompletionUserMessageContentMultimodal'

    ChatCompletionAssistantMessageParam:
      type: object
      required: [role]
      properties:
        content:
          type: string
          nullable: true
        role:
          type: string
          enum: ['assistant']
        name:
          type: string
        tool_calls:
          type: array
          items:
            $ref: '#/components/schemas/ToolChoice'
        function_call:
          type: object
          deprecated: true
          properties:
            arguments:
              type: string
            name:
              type: string
          required: [arguments, name]

    ChatCompletionFunctionMessageParam:
      type: object
      deprecated: true
      required: [content, role, name]
      properties:
        role:
          type: string
          enum: ['function']
        content:
          type: string
        name:
          type: string

    ChatCompletionToolMessageParam:
      type: object
      properties:
        role:
          type: string
          enum: ['tool']
        content:
          type: string
        tool_call_id:
          type: string
      required: [role, content, tool_call_id]

    # End Message Params

    ChatCompletionResponse:
      type: object
      properties:
        id:
          type: string
        choices:
          $ref: '#/components/schemas/ChatCompletionChoicesData'
        usage:
          $ref: '#/components/schemas/UsageData'
        created:
          type: integer
        model:
          type: string
        object:
          type: string
          enum:
            - chat.completion
        warnings:
          type: array
          items:
            $ref: '#/components/schemas/InferenceWarning'
      required: [choices, id, created, model, object]

    ChatCompletionStream:
      oneOf:
        - $ref: '#/components/schemas/ChatCompletionEvent'
        - $ref: '#/components/schemas/StreamSentinel'

    ChatCompletionEvent:
      type: object
      required: [data]
      properties:
        data:
          $ref: '#/components/schemas/ChatCompletionChunk'

    ChatCompletionChunk:
      type: object
      required: [id, object, created, choices, model]
      properties:
        id:
          type: string
        object:
          type: string
          enum:
            - chat.completion.chunk
        created:
          type: integer
        system_fingerprint:
          type: string
        model:
          type: string
          example: mistralai/Mixtral-8x7B-Instruct-v0.1
        choices:
          title: ChatCompletionChoices
          type: array
          items:
            type: object
            required: [index, delta, finish_reason]
            properties:
              index:
                type: integer
              finish_reason:
                $ref: '#/components/schemas/FinishReason'
                nullable: true
              logprobs:
                type: number
                nullable: true
              seed:
                type: integer
                nullable: true
              delta:
                title: ChatCompletionChoiceDelta
                type: object
                required: [role]
                properties:
                  token_id:
                    type: integer
                  role:
                    type: string
                    enum: ['system', 'user', 'assistant', 'function', 'tool']
                  content:
                    type: string
                    nullable: true
                  tool_calls:
                    type: array
                    items:
                      $ref: '#/components/schemas/ToolChoice'
                  function_call:
                    type: object
                    deprecated: true
                    nullable: true
                    properties:
                      arguments:
                        type: string
                      name:
                        type: string
                    required:
                      - arguments
                      - name
        usage:
          allOf:
            - $ref: '#/components/schemas/UsageData'
            - nullable: true
        warnings:
          type: array
          items:
            $ref: '#/components/schemas/InferenceWarning'
    AudioSpeechRequest:
      type: object
      required:
        - model
        - input
        - voice
      properties:
        model:
          description: >
            The name of the model to query.<br>
            <br>
            [See all of Together AI's chat models](https://docs.together.ai/docs/serverless-models#audio-models)
          example: cartesia/sonic
          anyOf:
            - type: string
              enum:
                - cartesia/sonic
            - type: string
        input:
          type: string
          description: Input text to generate the audio for
        voice:
          description: The voice to use for generating the audio. [View all supported voices here](https://docs.together.ai/docs/text-to-speech#voices-available).
          anyOf:
            - type: string
              enum:
                - laidback woman
                - polite man
                - storyteller lady
                - friendly sidekick
            - type: string
        response_format:
          type: string
          description: The format of audio output
          default: wav
          enum:
            - mp3
            - wav
            - raw
        language:
          type: string
          description: Language of input text
          default: en
          enum:
            - en
            - de
            - fr
            - es
            - hi
            - it
            - ja
            - ko
            - nl
            - pl
            - pt
            - ru
            - sv
            - tr
            - zh
        response_encoding:
          type: string
          description: Audio encoding of response
          default: pcm_f32le
          enum:
            - pcm_f32le
            - pcm_s16le
            - pcm_mulaw
            - pcm_alaw
        sample_rate:
          type: number
          default: 44100
          description: Sampling rate to use for the output audio
        stream:
          type: boolean
          default: false
          description: 'If true, output is streamed for several characters at a time instead of waiting for the full response. The stream terminates with `data: [DONE]`. If false, return the encoded audio as octet stream'

    AudioTranscriptionRequest:
      type: object
      required:
        - file
      properties:
        file:
          oneOf:
            - $ref: '#/components/schemas/AudioFileBinary'
            - $ref: '#/components/schemas/AudioFileUrl'
          description: Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.
        model:
          type: string
          description: Model to use for transcription
          default: openai/whisper-large-v3
          enum:
            - openai/whisper-large-v3
        language:
          type: string
          description: Optional ISO 639-1 language code. If `auto` is provided, language is auto-detected.
          default: en
          example: en
        prompt:
          type: string
          description: Optional text to bias decoding.
        response_format:
          type: string
          description: The format of the response
          default: json
          enum:
            - json
            - verbose_json
        temperature:
          type: number
          format: float
          description: Sampling temperature between 0.0 and 1.0
          default: 0.0
          minimum: 0.0
          maximum: 1.0
        timestamp_granularities:
          oneOf:
            - type: string
              enum:
                - segment
                - word
            - type: array
              items:
                type: string
                enum:
                  - segment
                  - word
              uniqueItems: true
              minItems: 1
              maxItems: 2
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          default: segment
          example: ['word', 'segment']

    AudioTranscriptionResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioTranscriptionJsonResponse'
        - $ref: '#/components/schemas/AudioTranscriptionVerboseJsonResponse'

    AudioTranscriptionJsonResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
          description: The transcribed text
          example: Hello, world!

    AudioTranscriptionVerboseJsonResponse:
      type: object
      required:
        - task
        - language
        - duration
        - text
        - segments
      properties:
        task:
          type: string
          description: The task performed
          enum:
            - transcribe
            - translate
          example: transcribe
        language:
          type: string
          description: The language of the audio
          example: english
        duration:
          type: number
          format: float
          description: The duration of the audio in seconds
          example: 3.5
        text:
          type: string
          description: The transcribed text
          example: Hello, world!
        segments:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionSegment'
          description: Array of transcription segments
        words:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionWord'
          description: Array of transcription words (only when timestamp_granularities includes 'word')

    AudioTranscriptionSegment:
      type: object
      required:
        - id
        - start
        - end
        - text
      properties:
        id:
          type: integer
          description: Unique identifier for the segment
          example: 0
        start:
          type: number
          format: float
          description: Start time of the segment in seconds
          example: 0.0
        end:
          type: number
          format: float
          description: End time of the segment in seconds
          example: 3.5
        text:
          type: string
          description: The text content of the segment
          example: Hello, world!

    AudioTranscriptionWord:
      type: object
      required:
        - word
        - start
        - end
      properties:
        word:
          type: string
          description: The word
          example: Hello
        start:
          type: number
          format: float
          description: Start time of the word in seconds
          example: 0.0
        end:
          type: number
          format: float
          description: End time of the word in seconds
          example: 0.5

    AudioTranslationRequest:
      type: object
      required:
        - file
      properties:
        file:
          oneOf:
            - type: string
              format: binary
              description: Audio file to translate
            - type: string
              format: uri
              description: Public HTTP/HTTPS URL to audio file
          description: Audio file upload or public HTTP/HTTPS URL. Supported formats .wav, .mp3, .m4a, .webm, .flac.
        model:
          type: string
          description: Model to use for translation
          default: openai/whisper-large-v3
          enum:
            - openai/whisper-large-v3
        language:
          type: string
          description: Target output language. Optional ISO 639-1 language code. If omitted, language is set to English.
          default: en
          example: en
        prompt:
          type: string
          description: Optional text to bias decoding.
        response_format:
          type: string
          description: The format of the response
          default: json
          enum:
            - json
            - verbose_json
        temperature:
          type: number
          format: float
          description: Sampling temperature between 0.0 and 1.0
          default: 0.0
          minimum: 0.0
          maximum: 1.0
        timestamp_granularities:
          oneOf:
            - type: string
              enum:
                - segment
                - word
            - type: array
              items:
                type: string
                enum:
                  - segment
                  - word
              uniqueItems: true
              minItems: 1
              maxItems: 2
          description: Controls level of timestamp detail in verbose_json. Only used when response_format is verbose_json. Can be a single granularity or an array to get multiple levels.
          default: segment
          example: ['word', 'segment']

    AudioTranslationResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioTranslationJsonResponse'
        - $ref: '#/components/schemas/AudioTranslationVerboseJsonResponse'

    AudioTranslationJsonResponse:
      type: object
      required:
        - text
      properties:
        text:
          type: string
          description: The translated text
          example: Hello, world!

    AudioTranslationVerboseJsonResponse:
      type: object
      required:
        - task
        - language
        - duration
        - text
        - segments
      properties:
        task:
          type: string
          description: The task performed
          enum:
            - transcribe
            - translate
          example: translate
        language:
          type: string
          description: The target language of the translation
          example: english
        duration:
          type: number
          format: float
          description: The duration of the audio in seconds
          example: 3.5
        text:
          type: string
          description: The translated text
          example: Hello, world!
        segments:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionSegment'
          description: Array of translation segments
        words:
          type: array
          items:
            $ref: '#/components/schemas/AudioTranscriptionWord'
          description: Array of translation words (only when timestamp_granularities includes 'word')

    AudioSpeechStreamResponse:
      oneOf:
        - $ref: '#/components/schemas/AudioSpeechStreamEvent'
        - $ref: '#/components/schemas/StreamSentinel'

    AudioSpeechStreamEvent:
      type: object
      required: [data]
      properties:
        data:
          $ref: '#/components/schemas/AudioSpeechStreamChunk'

    AudioSpeechStreamChunk:
      type: object
      required: [object, model, b64]
      properties:
        object:
          type: string
          enum:
            - audio.tts.chunk
        model:
          type: string
          example: cartesia/sonic
        b64:
          type: string
          description: base64 encoded audio stream

    StreamSentinel:
      type: object
      required: [data]
      properties:
        data:
          title: stream_signal
          type: string
          enum:
            - '[DONE]'

    ChatCompletionToken:
      type: object
      required: [id, text, logprob, special]
      properties:
        id:
          type: integer
        text:
          type: string
        logprob:
          type: number
        special:
          type: boolean

    ChatCompletionChoice:
      type: object
      required: [index, delta, finish_reason]
      properties:
        index:
          type: integer
        finish_reason:
          $ref: '#/components/schemas/FinishReason'
        logprobs:
          $ref: '#/components/schemas/LogprobsPart'
        delta:
          title: ChatCompletionChoiceDelta
          type: object
          required: [role]
          properties:
            token_id:
              type: integer
            role:
              type: string
              enum: ['system', 'user', 'assistant', 'function', 'tool']
            content:
              type: string
              nullable: true
            tool_calls:
              type: array
              items:
                $ref: '#/components/schemas/ToolChoice'
            function_call:
              type: object
              deprecated: true
              nullable: true
              properties:
                arguments:
                  type: string
                name:
                  type: string
              required:
                - arguments
                - name

    EmbeddingsRequest:
      type: object
      required:
        - model
        - input
      properties:
        model:
          type: string
          description: >
            The name of the embedding model to use.<br>
            <br>
            [See all of Together AI's embedding models](https://docs.together.ai/docs/serverless-models#embedding-models)
          example: togethercomputer/m2-bert-80M-8k-retrieval
          anyOf:
            - type: string
              enum:
                - WhereIsAI/UAE-Large-V1
                - BAAI/bge-large-en-v1.5
                - BAAI/bge-base-en-v1.5
                - togethercomputer/m2-bert-80M-8k-retrieval
            - type: string
        input:
          oneOf:
            - type: string
              description: A string providing the text for the model to embed.
              example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
            - type: array
              items:
                type: string
                description: A string providing the text for the model to embed.
                example: Our solar system orbits the Milky Way galaxy at about 515,000 mph
          example: Our solar system orbits the Milky Way galaxy at about 515,000 mph

    EmbeddingsResponse:
      type: object
      required:
        - object
        - model
        - data
      properties:
        object:
          type: string
          enum:
            - list
        model:
          type: string
        data:
          type: array
          items:
            type: object
            required: [index, object, embedding]
            properties:
              object:
                type: string
                enum:
                  - embedding
              embedding:
                type: array
                items:
                  type: number
              index:
                type: integer

    ModelInfoList:
      type: array
      items:
        $ref: '#/components/schemas/ModelInfo'
    ModelInfo:
      type: object
      required: [id, object, created, type]
      properties:
        id:
          type: string
          example: 'Austism/chronos-hermes-13b'
        object:
          type: string
          example: 'model'
        created:
          type: integer
          example: 1692896905
        type:
          enum:
            - chat
            - language
            - code
            - image
            - embedding
            - moderation
            - rerank
          example: 'chat'
        display_name:
          type: string
          example: 'Chronos Hermes (13B)'
        organization:
          type: string
          example: 'Austism'
        link:
          type: string
        license:
          type: string
          example: 'other'
        context_length:
          type: integer
          example: 2048
        pricing:
          $ref: '#/components/schemas/Pricing'

    ModelUploadRequest:
      type: object
      required:
        - model_name
        - model_source
      properties:
        model_name:
          type: string
          description: The name to give to your uploaded model
          example: 'Qwen2.5-72B-Instruct'
        model_source:
          type: string
          description: The source location of the model (Hugging Face repo or S3 path)
          example: 'unsloth/Qwen2.5-72B-Instruct'
        model_type:
          type: string
          description: Whether the model is a full model or an adapter
          default: 'model'
          enum:
            - model
            - adapter
          example: 'model'
        hf_token:
          type: string
          description: Hugging Face token (if uploading from Hugging Face)
          example: 'hf_examplehuggingfacetoken'
        description:
          type: string
          description: A description of your model
          example: 'Finetuned Qwen2.5-72B-Instruct by Unsloth'
        base_model:
          type: string
          description: The base model to use for an adapter if setting it to run against a serverless pool.  Only used for model_type `adapter`.
          example: 'Qwen/Qwen2.5-72B-Instruct'
        lora_model:
          type: string
          description: The lora pool to use for an adapter if setting it to run against, say, a dedicated pool.  Only used for model_type `adapter`.
          example: 'my_username/Qwen2.5-72B-Instruct-lora'

    ModelUploadSuccessResponse:
      type: object
      required:
        - data
        - message
      properties:
        data:
          type: object
          required:
            - job_id
            - model_name
            - model_id
            - model_source
          properties:
            job_id:
              type: string
              example: 'job-a15dad11-8d8e-4007-97c5-a211304de284'
            model_name:
              type: string
              example: 'necolinehubner/Qwen2.5-72B-Instruct'
            model_id:
              type: string
              example: 'model-c0e32dfc-637e-47b2-bf4e-e9b2e58c9da7'
            model_source:
              type: string
              example: 'huggingface'
        message:
          type: string
          example: 'Processing model weights. Job created.'

    ImageResponse:
      type: object
      properties:
        id:
          type: string
        model:
          type: string
        object:
          enum:
            - list
          example: 'list'
        data:
          type: array
          items:
            oneOf:
              - $ref: '#/components/schemas/ImageResponseDataB64'
              - $ref: '#/components/schemas/ImageResponseDataUrl'
            discriminator:
              propertyName: type
      required:
        - id
        - model
        - object
        - data

    ImageResponseDataB64:
      type: object
      required: [index, b64_json, type]
      properties:
        index:
          type: integer
        b64_json:
          type: string
        type:
          type: string
          enum: [b64_json]

    ImageResponseDataUrl:
      type: object
      required: [index, url, type]
      properties:
        index:
          type: integer
        url:
          type: string
        type:
          type: string
          enum: [url]

    JobInfoSuccessResponse:
      type: object
      required:
        - type
        - job_id
        - status
        - status_updates
        - args
        - created_at
        - updated_at
      properties:
        type:
          type: string
          example: 'model_upload'
        job_id:
          type: string
          example: 'job-a15dad11-8d8e-4007-97c5-a211304de284'
        status:
          type: string
          enum: ['Queued', 'Running', 'Complete', 'Failed']
          example: 'Complete'
        status_updates:
          type: array
          items:
            type: object
            required:
              - status
              - message
              - timestamp
            properties:
              status:
                type: string
                example: 'Complete'
              message:
                type: string
                example: 'Job is Complete'
              timestamp:
                type: string
                format: date-time
                example: '2025-03-11T22:36:12Z'
        args:
          type: object
          properties:
            description:
              type: string
              example: 'Finetuned Qwen2.5-72B-Instruct by Unsloth'
            modelName:
              type: string
              example: 'necolinehubner/Qwen2.5-72B-Instruct'
            modelSource:
              type: string
              example: 'unsloth/Qwen2.5-72B-Instruct'
        created_at:
          type: string
          format: date-time
          example: '2025-03-11T22:05:43Z'
        updated_at:
          type: string
          format: date-time
          example: '2025-03-11T22:36:12Z'

    JobsInfoSuccessResponse:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/JobInfoSuccessResponse'

    Pricing:
      type: object
      required: [hourly, input, output, base, finetune]
      properties:
        hourly:
          type: number
          example: 0
        input:
          type: number
          example: 0.3
        output:
          type: number
          example: 0.3
        base:
          type: number
          example: 0
        finetune:
          type: number
          example: 0

    ToolsPart:
      type: object
      properties:
        type:
          type: string
          example: 'tool_type'
        function:
          type: object
          properties:
            description:
              type: string
              example: 'A description of the function.'
            name:
              type: string
              example: 'function_name'
            parameters:
              type: object
              additionalProperties: true
              description: 'A map of parameter names to their values.'
    ToolChoice:
      type: object
      required: [id, type, function, index]
      properties:
        # TODO: is this the right place for index?
        index:
          type: number
        id:
          type: string
        type:
          type: string
          enum: ['function']
        function:
          type: object
          required: [name, arguments]
          properties:
            name:
              type: string
              example: 'function_name'
            arguments:
              type: string

    FileResponse:
      type: object
      required:
        - id
        - object
        - created_at
        - filename
        - bytes
        - purpose
        - FileType
        - Processed
        - LineCount
      properties:
        id:
          type: string
        object:
          type: string
          example: 'file'
        created_at:
          type: integer
          example: 1715021438
        filename:
          type: string
          example: 'my_file.jsonl'
        bytes:
          type: integer
          example: 2664
        purpose:
          $ref: '#/components/schemas/FilePurpose'
        Processed:
          type: boolean
        FileType:
          $ref: '#/components/schemas/FileType'
        LineCount:
          type: integer
    FileList:
      required:
        - data
      type: object
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FileResponse'
    FileObject:
      type: object
      properties:
        object:
          type: string
        id:
          type: string
        filename:
          type: string
        size:
          type: integer
    FilePurpose:
      type: string
      description: The purpose of the file
      example: 'fine-tune'
      enum:
        - fine-tune
        - eval
        - eval-sample
        - eval-output
        - eval-summary
        - batch-generated
        - batch-api
    FileType:
      type: string
      description: The type of the file
      default: 'jsonl'
      example: 'jsonl'
      enum:
        - 'csv'
        - 'jsonl'
        - 'parquet'
    FileDeleteResponse:
      type: object
      properties:
        id:
          type: string
        deleted:
          type: boolean
    FinetuneResponse:
      type: object
      required:
        - id
        - status
      properties:
        id:
          type: string
          format: uuid
        training_file:
          type: string
        validation_file:
          type: string
        model:
          type: string
        model_output_name:
          type: string
        model_output_path:
          type: string
        trainingfile_numlines:
          type: integer
        trainingfile_size:
          type: integer
        created_at:
          type: string
        updated_at:
          type: string
        n_epochs:
          type: integer
        n_checkpoints:
          type: integer
        n_evals:
          type: integer
        batch_size:
          oneOf:
            - type: integer
            - type: string
              enum:
                - max
          default: 'max'
        learning_rate:
          type: number
        lr_scheduler:
          type: object
          $ref: '#/components/schemas/LRScheduler'
        warmup_ratio:
          type: number
        max_grad_norm:
          type: number
          format: float
        weight_decay:
          type: number
          format: float
        eval_steps:
          type: integer
        train_on_inputs:
          oneOf:
            - type: boolean
            - type: string
              enum:
                - auto
          default: auto
        training_method:
          type: object
          oneOf:
            - $ref: '#/components/schemas/TrainingMethodSFT'
            - $ref: '#/components/schemas/TrainingMethodDPO'
        training_type:
          type: object
          oneOf:
            - $ref: '#/components/schemas/FullTrainingType'
            - $ref: '#/components/schemas/LoRATrainingType'
        status:
          $ref: '#/components/schemas/FinetuneJobStatus'
        job_id:
          type: string
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
        token_count:
          type: integer
        param_count:
          type: integer
        total_price:
          type: integer
        epochs_completed:
          type: integer
        queue_depth:
          type: integer
        wandb_project_name:
          type: string
        wandb_url:
          type: string
        from_checkpoint:
          type: string
        from_hf_model:
          type: string
        hf_model_revision:
          type: string

    FinetuneResponseTruncated:
      type: object
      description: A truncated version of the fine-tune response, used for POST /fine-tunes, GET /fine-tunes and POST /fine-tunes/{id}/cancel endpoints
      required:
        - id
        - status
        - created_at
        - updated_at
      example:
        id: ft-01234567890123456789
        status: completed
        created_at: '2023-05-17T17:35:45.123Z'
        updated_at: '2023-05-17T18:46:23.456Z'
        user_id: 'user_01234567890123456789'
        owner_address: 'user@example.com'
        total_price: 1500
        token_count: 850000
        events: [] # FineTuneTruncated object has no events
        model: 'meta-llama/Llama-2-7b-hf'
        model_output_name: 'mynamespace/meta-llama/Llama-2-7b-hf-32162631'
        n_epochs: 3
        training_file: 'file-01234567890123456789'
        wandb_project_name: 'my-finetune-project'
      properties:
        id:
          type: string
          description: Unique identifier for the fine-tune job
        status:
          $ref: '#/components/schemas/FinetuneJobStatus'
        created_at:
          type: string
          format: date-time
          description: Creation timestamp of the fine-tune job
        updated_at:
          type: string
          format: date-time
          description: Last update timestamp of the fine-tune job
        user_id:
          type: string
          description: Identifier for the user who created the job
        owner_address:
          type: string
          description: Owner address information
        total_price:
          type: integer
          description: Total price for the fine-tuning job
        token_count:
          type: integer
          description: Count of tokens processed
        events:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
          description: Events related to this fine-tune job
        # FineTuneUserParams fields
        training_file:
          type: string
          description: File-ID of the training file
        validation_file:
          type: string
          description: File-ID of the validation file
        model:
          type: string
          description: Base model used for fine-tuning
        model_output_name:
          type: string
        suffix:
          type: string
          description: Suffix added to the fine-tuned model name
        n_epochs:
          type: integer
          description: Number of training epochs
        n_evals:
          type: integer
          description: Number of evaluations during training
        n_checkpoints:
          type: integer
          description: Number of checkpoints saved during training
        batch_size:
          type: integer
          description: Batch size used for training
        training_type:
          oneOf:
            - $ref: '#/components/schemas/FullTrainingType'
            - $ref: '#/components/schemas/LoRATrainingType'
          description: Type of training used (full or LoRA)
        training_method:
          oneOf:
            - $ref: '#/components/schemas/TrainingMethodSFT'
            - $ref: '#/components/schemas/TrainingMethodDPO'
          description: Method of training used
        learning_rate:
          type: number
          format: float
          description: Learning rate used for training
        lr_scheduler:
          $ref: '#/components/schemas/LRScheduler'
          description: Learning rate scheduler configuration
        warmup_ratio:
          type: number
          format: float
          description: Ratio of warmup steps
        max_grad_norm:
          type: number
          format: float
          description: Maximum gradient norm for clipping
        weight_decay:
          type: number
          format: float
          description: Weight decay value used
        wandb_project_name:
          type: string
          description: Weights & Biases project name
        wandb_name:
          type: string
          description: Weights & Biases run name
        from_checkpoint:
          type: string
          description: Checkpoint used to continue training
        from_hf_model:
          type: string
          description: Hugging Face Hub repo to start training from
        hf_model_revision:
          type: string
          description: The revision of the Hugging Face Hub model to continue training from

    FinetuneJobStatus:
      type: string
      enum:
        - pending
        - queued
        - running
        - compressing
        - uploading
        - cancel_requested
        - cancelled
        - error
        - completed

    FinetuneEventLevels:
      type: string
      enum:
        - null
        - info
        - warning
        - error
        - legacy_info
        - legacy_iwarning
        - legacy_ierror
    FinetuneEventType:
      type: string
      enum:
        - job_pending
        - job_start
        - job_stopped
        - model_downloading
        - model_download_complete
        - training_data_downloading
        - training_data_download_complete
        - validation_data_downloading
        - validation_data_download_complete
        - wandb_init
        - training_start
        - checkpoint_save
        - billing_limit
        - epoch_complete
        - training_complete
        - model_compressing
        - model_compression_complete
        - model_uploading
        - model_upload_complete
        - job_complete
        - job_error
        - cancel_requested
        - job_restarted
        - refund
        - warning

    FinetuneTruncatedList:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FinetuneResponseTruncated'
    FinetuneListEvents:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneEvent'
    FineTuneEvent:
      type: object
      required:
        - object
        - created_at
        - message
        - type
        - param_count
        - token_count
        - total_steps
        - wandb_url
        - step
        - checkpoint_path
        - model_path
        - training_offset
        - hash
      properties:
        object:
          type: string
          enum: [fine-tune-event]
        created_at:
          type: string
        level:
          anyOf:
            - $ref: '#/components/schemas/FinetuneEventLevels'
        message:
          type: string
        type:
          $ref: '#/components/schemas/FinetuneEventType'
        param_count:
          type: integer
        token_count:
          type: integer
        total_steps:
          type: integer
        wandb_url:
          type: string
        step:
          type: integer
        checkpoint_path:
          type: string
        model_path:
          type: string
        training_offset:
          type: integer
        hash:
          type: string

    FinetuneListCheckpoints:
      type: object
      required:
        - data
      properties:
        data:
          type: array
          items:
            $ref: '#/components/schemas/FineTuneCheckpoint'
    FineTuneCheckpoint:
      type: object
      required:
        - step
        - path
        - created_at
        - checkpoint_type
      properties:
        step:
          type: integer
        created_at:
          type: string
        path:
          type: string
        checkpoint_type:
          type: string

    FinetuneDownloadResult:
      type: object
      properties:
        object:
          enum:
            - null
            - local
        id:
          type: string
        checkpoint_step:
          type: integer
        filename:
          type: string
        size:
          type: integer

    FullTrainingType:
      type: object
      properties:
        type:
          type: string
          enum: ['Full']
      required:
        - type
    LoRATrainingType:
      type: object
      properties:
        type:
          type: string
          enum: ['Lora']
        lora_r:
          type: integer
        lora_alpha:
          type: integer
        lora_dropout:
          type: number
          format: float
          default: 0.0
        lora_trainable_modules:
          type: string
          default: 'all-linear'
      required:
        - type
        - lora_r
        - lora_alpha

    TrainingMethodSFT:
      type: object
      properties:
        method:
          type: string
          enum: ['sft']
        train_on_inputs:
          oneOf:
            - type: boolean
            - type: string
              enum:
                - auto
          type: boolean
          default: auto
          description: Whether to mask the user messages in conversational data or prompts in instruction data.
      required:
        - method
        - train_on_inputs
    TrainingMethodDPO:
      type: object
      properties:
        method:
          type: string
          enum: ['dpo']
        dpo_beta:
          type: number
          format: float
          default: 0.1
        rpo_alpha:
          type: number
          format: float
          default: 0.0
        dpo_normalize_logratios_by_length:
          type: boolean
          default: false
        dpo_reference_free:
          type: boolean
          default: false
        simpo_gamma:
          type: number
          format: float
          default: 0.0
      required:
        - method

    LRScheduler:
      type: object
      properties:
        lr_scheduler_type:
          type: string
          enum:
            - linear
            - cosine
        lr_scheduler_args:
          oneOf:
            - $ref: '#/components/schemas/LinearLRSchedulerArgs'
            - $ref: '#/components/schemas/CosineLRSchedulerArgs'
      required:
        - lr_scheduler_type
    CosineLRSchedulerArgs:
      type: object
      properties:
        min_lr_ratio:
          type: number
          format: float
          default: 0.0
          description: The ratio of the final learning rate to the peak learning rate
        num_cycles:
          type: number
          format: float
          default: 0.5
          description: Number or fraction of cycles for the cosine learning rate scheduler
      required:
        - min_lr_ratio
        - num_cycles
    LinearLRSchedulerArgs:
      type: object
      properties:
        min_lr_ratio:
          type: number
          format: float
          default: 0.0
          description: The ratio of the final learning rate to the peak learning rate

    Autoscaling:
      type: object
      description: Configuration for automatic scaling of replicas based on demand.
      required:
        - min_replicas
        - max_replicas
      properties:
        min_replicas:
          type: integer
          format: int32
          description: The minimum number of replicas to maintain, even when there is no load
          examples:
            - 2
        max_replicas:
          type: integer
          format: int32
          description: The maximum number of replicas to scale up to under load
          examples:
            - 5

    HardwareSpec:
      type: object
      description: Detailed specifications of a hardware configuration
      required:
        - gpu_type
        - gpu_link
        - gpu_memory
        - gpu_count
      properties:
        gpu_type:
          type: string
          description: The type/model of GPU
          examples:
            - a100-80gb
        gpu_link:
          type: string
          description: The GPU interconnect technology
          examples:
            - sxm
        gpu_memory:
          type: number
          format: float
          description: Amount of GPU memory in GB
          examples:
            - 80
        gpu_count:
          type: integer
          format: int32
          description: Number of GPUs in this configuration
          examples:
            - 2

    EndpointPricing:
      type: object
      description: Pricing details for using an endpoint
      required:
        - cents_per_minute
      properties:
        cents_per_minute:
          type: number
          format: float
          description: Cost per minute of endpoint uptime in cents
          examples:
            - 5.42

    HardwareAvailability:
      type: object
      description: Indicates the current availability status of a hardware configuration
      required:
        - status
      properties:
        status:
          type: string
          description: The availability status of the hardware configuration
          enum:
            - available
            - unavailable
            - insufficient

    HardwareWithStatus:
      type: object
      description: Hardware configuration details with optional availability status
      required:
        - object
        - id
        - pricing
        - specs
        - updated_at
      properties:
        object:
          type: string
          enum:
            - hardware
        id:
          type: string
          description: Unique identifier for the hardware configuration
          examples:
            - 2x_nvidia_a100_80gb_sxm
        pricing:
          $ref: '#/components/schemas/EndpointPricing'
        specs:
          $ref: '#/components/schemas/HardwareSpec'
        availability:
          $ref: '#/components/schemas/HardwareAvailability'
        updated_at:
          type: string
          format: date-time
          description: Timestamp of when the hardware status was last updated

    CreateEndpointRequest:
      type: object
      required:
        - model
        - hardware
        - autoscaling
      properties:
        display_name:
          type: string
          description: A human-readable name for the endpoint
          examples:
            - My Llama3 70b endpoint
        model:
          type: string
          description: The model to deploy on this endpoint
          examples:
            - meta-llama/Llama-3-8b-chat-hf
        hardware:
          type: string
          description: The hardware configuration to use for this endpoint
          examples:
            - 1x_nvidia_a100_80gb_sxm
        autoscaling:
          $ref: '#/components/schemas/Autoscaling'
          description: Configuration for automatic scaling of the endpoint
        disable_prompt_cache:
          type: boolean
          description: Whether to disable the prompt cache for this endpoint
          default: false
        disable_speculative_decoding:
          type: boolean
          description: Whether to disable speculative decoding for this endpoint
          default: false
        state:
          type: string
          description: The desired state of the endpoint
          enum:
            - STARTED
            - STOPPED
          default: STARTED
          example: STARTED
        inactive_timeout:
          type: integer
          description: The number of minutes of inactivity after which the endpoint will be automatically stopped. Set to null, omit or set to 0 to disable automatic timeout.
          nullable: true
          example: 60

    DedicatedEndpoint:
      type: object
      description: Details about a dedicated endpoint deployment
      required:
        - object
        - id
        - name
        - display_name
        - model
        - hardware
        - type
        - owner
        - state
        - autoscaling
        - created_at
      properties:
        object:
          type: string
          enum:
            - endpoint
          description: The type of object
          example: endpoint
        id:
          type: string
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
        name:
          type: string
          description: System name for the endpoint
          example: devuser/meta-llama/Llama-3-8b-chat-hf-a32b82a1
        display_name:
          type: string
          description: Human-readable name for the endpoint
          example: My Llama3 70b endpoint
        model:
          type: string
          description: The model deployed on this endpoint
          example: meta-llama/Llama-3-8b-chat-hf
        hardware:
          type: string
          description: The hardware configuration used for this endpoint
          example: 1x_nvidia_a100_80gb_sxm
        type:
          type: string
          enum:
            - dedicated
          description: The type of endpoint
          example: dedicated
        owner:
          type: string
          description: The owner of this endpoint
          example: devuser
        state:
          type: string
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          description: Current state of the endpoint
          example: STARTED
        autoscaling:
          $ref: '#/components/schemas/Autoscaling'
          description: Configuration for automatic scaling of the endpoint
        created_at:
          type: string
          format: date-time
          description: Timestamp when the endpoint was created
          example: 2025-02-04T10:43:55.405Z

    ListEndpoint:
      type: object
      description: Details about an endpoint when listed via the list endpoint
      required:
        - id
        - object
        - name
        - model
        - type
        - owner
        - state
        - created_at
      properties:
        object:
          type: string
          enum:
            - endpoint
          description: The type of object
          example: endpoint
        id:
          type: string
          description: Unique identifier for the endpoint
          example: endpoint-d23901de-ef8f-44bf-b3e7-de9c1ca8f2d7
        name:
          type: string
          description: System name for the endpoint
          example: allenai/OLMo-7B
        model:
          type: string
          description: The model deployed on this endpoint
          example: allenai/OLMo-7B
        type:
          type: string
          enum:
            - serverless
            - dedicated
          description: The type of endpoint
          example: serverless
        owner:
          type: string
          description: The owner of this endpoint
          example: together
        state:
          type: string
          enum:
            - PENDING
            - STARTING
            - STARTED
            - STOPPING
            - STOPPED
            - ERROR
          description: Current state of the endpoint
          example: STARTED
        created_at:
          type: string
          format: date-time
          description: Timestamp when the endpoint was created
          example: 2024-02-28T21:34:35.444Z

    DisplayorExecuteOutput:
      properties:
        data:
          properties:
            application/geo+json:
              type: object
            application/javascript:
              type: string
            application/json:
              type: object
            application/pdf:
              format: byte
              type: string
            application/vnd.vega.v5+json:
              type: object
            application/vnd.vegalite.v4+json:
              type: object
            image/gif:
              format: byte
              type: string
            image/jpeg:
              format: byte
              type: string
            image/png:
              format: byte
              type: string
            image/svg+xml:
              type: string
            text/html:
              type: string
            text/latex:
              type: string
            text/markdown:
              type: string
            text/plain:
              type: string
          type: object
        type:
          enum:
            - display_data
            - execute_result
          type: string
      required:
        - type
        - data
      title: DisplayorExecuteOutput

    Error:
      oneOf:
        - type: string
        - additionalProperties: true
          type: object
      title: Error

    ErrorOutput:
      title: ErrorOutput
      description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
      properties:
        data:
          type: string
        type:
          enum:
            - error
          type: string
      required:
        - type
        - data

    ExecuteRequest:
      title: ExecuteRequest
      required:
        - language
        - code
      properties:
        code:
          description: 'Code snippet to execute.'
          example: "print('Hello, world!')"
          type: string
        files:
          description: Files to upload to the session. If present, files will be uploaded before executing the given code.
          items:
            properties:
              content:
                type: string
              encoding:
                description: Encoding of the file content. Use `string` for text files such as code, and `base64` for binary files, such as images.
                enum:
                  - string
                  - base64
                type: string
              name:
                type: string
            required:
              - name
              - encoding
              - content
            type: object
          type: array
        language:
          default: python
          description: Programming language for the code to execute. Currently only supports Python, but more will be added.
          enum:
            - python
        session_id:
          description: Identifier of the current session. Used to make follow-up calls. Requests will return an error if the session does not belong to the caller or has expired.
          example: ses_abcDEF123
          nullable: false
          type: string

    ExecuteResponse:
      title: ExecuteResponse
      type: object
      description: 'The result of the execution. If successful, `data` contains the result and `errors` will be null. If unsuccessful, `data` will be null and `errors` will contain the errors.'
      oneOf:
        - title: SuccessfulExecution
          type: object
          required: [data, errors]
          properties:
            errors:
              type: 'null'
            data:
              type: object
              nullable: false
              required: [session_id, outputs]
              properties:
                outputs:
                  type: array
                  items:
                    discriminator:
                      propertyName: type
                    oneOf:
                      - title: StreamOutput
                        description: Outputs that were printed to stdout or stderr
                        type: object
                        required: [type, data]
                        properties:
                          type:
                            enum:
                              - stdout
                              - stderr
                            type: string
                          data:
                            type: string
                      - description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
                        properties:
                          data:
                            type: string
                          type:
                            enum:
                              - error
                            type: string
                        required:
                          - type
                          - data
                        title: ErrorOutput
                      - properties:
                          data:
                            properties:
                              application/geo+json:
                                type: object
                                additionalProperties: true
                              application/javascript:
                                type: string
                              application/json:
                                type: object
                                additionalProperties: true
                              application/pdf:
                                format: byte
                                type: string
                              application/vnd.vega.v5+json:
                                type: object
                                additionalProperties: true
                              application/vnd.vegalite.v4+json:
                                type: object
                                additionalProperties: true
                              image/gif:
                                format: byte
                                type: string
                              image/jpeg:
                                format: byte
                                type: string
                              image/png:
                                format: byte
                                type: string
                              image/svg+xml:
                                type: string
                              text/html:
                                type: string
                              text/latex:
                                type: string
                              text/markdown:
                                type: string
                              text/plain:
                                type: string
                            type: object
                          type:
                            enum:
                              - display_data
                              - execute_result
                            type: string
                        required:
                          - type
                          - data
                        title: DisplayorExecuteOutput
                    title: InterpreterOutput
                session_id:
                  type: string
                  description: Identifier of the current session. Used to make follow-up calls.
                  example: ses_abcDEF123
                  nullable: false
                status:
                  type: string
                  enum:
                    - success
                  description: Status of the execution. Currently only supports success.
        - title: FailedExecution
          type: object
          required: [data, errors]
          properties:
            data:
              type: 'null'
            errors:
              type: array
              items:
                title: Error
                oneOf:
                  - type: string
                  - type: object
                    additionalProperties: true

    InterpreterOutput:
      discriminator:
        propertyName: type
      oneOf:
        - description: Outputs that were printed to stdout or stderr
          properties:
            data:
              type: string
            type:
              enum:
                - stdout
                - stderr
              type: string
          required:
            - type
            - data
          title: StreamOutput
        - description: Errors and exceptions that occurred. If this output type is present, your code did not execute successfully.
          properties:
            data:
              type: string
            type:
              enum:
                - error
              type: string
          required:
            - type
            - data
          title: ErrorOutput
        - properties:
            data:
              properties:
                application/geo+json:
                  type: object
                application/javascript:
                  type: string
                application/json:
                  type: object
                application/pdf:
                  format: byte
                  type: string
                application/vnd.vega.v5+json:
                  type: object
                application/vnd.vegalite.v4+json:
                  type: object
                image/gif:
                  format: byte
                  type: string
                image/jpeg:
                  format: byte
                  type: string
                image/png:
                  format: byte
                  type: string
                image/svg+xml:
                  type: string
                text/html:
                  type: string
                text/latex:
                  type: string
                text/markdown:
                  type: string
                text/plain:
                  type: string
              type: object
            type:
              enum:
                - display_data
                - execute_result
              type: string
          required:
            - type
            - data
          title: DisplayorExecuteOutput
      title: InterpreterOutput

    Response:
      properties:
        errors:
          items:
            oneOf:
              - type: string
              - additionalProperties: true
                type: object
            title: Error
          type: array
      title: Response
      type: object

    SessionListResponse:
      allOf:
        - properties:
            errors:
              items:
                oneOf:
                  - type: string
                  - additionalProperties: true
                    type: object
                title: Error
              type: array
          title: Response
          type: object
        - properties:
            data:
              properties:
                sessions:
                  items:
                    properties:
                      execute_count:
                        type: integer
                      expires_at:
                        format: date-time
                        type: string
                      id:
                        description: Session Identifier. Used to make follow-up calls.
                        example: ses_abcDEF123
                        type: string
                      last_execute_at:
                        format: date-time
                        type: string
                      started_at:
                        format: date-time
                        type: string
                    required:
                      - execute_count
                      - expires_at
                      - id
                      - last_execute_at
                      - started_at
                    type: object
                  type: array
              required:
                - sessions
          type: object
      title: SessionListResponse
      type: object

    StreamOutput:
      description: Outputs that were printed to stdout or stderr
      properties:
        data:
          type: string
        type:
          enum:
            - stdout
            - stderr
          type: string
      required:
        - type
        - data
      title: StreamOutput

    CreateBatchRequest:
      type: object
      required: [endpoint, input_file_id]
      properties:
        endpoint:
          type: string
          description: The endpoint to use for batch processing
          example: '/v1/chat/completions'
        input_file_id:
          type: string
          description: ID of the uploaded input file containing batch requests
          example: 'file-abc123def456ghi789'
        completion_window:
          type: string
          description: Time window for batch completion (optional)
          example: '24h'
        priority:
          type: integer
          description: Priority for batch processing (optional)
          example: 1
        model_id:
          type: string
          description: 'Model to use for processing batch requests'
          example: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'
    BatchErrorResponse:
      type: object
      properties:
        error:
          type: string
    BatchJobWithWarning:
      type: object
      properties:
        job:
          $ref: '#/components/schemas/BatchJob'
        warning:
          type: string
    BatchJob:
      type: object
      properties:
        id:
          type: string
          format: uuid
          example: '01234567-8901-2345-6789-012345678901'
        user_id:
          type: string
          example: 'user_789xyz012'
        input_file_id:
          type: string
          example: 'file-input123abc456def'
        file_size_bytes:
          type: integer
          format: int64
          example: 1048576
          description: 'Size of input file in bytes'
        status:
          $ref: '#/components/schemas/BatchJobStatus'
        job_deadline:
          type: string
          format: date-time
          example: '2024-01-15T15:30:00Z'
        created_at:
          type: string
          format: date-time
          example: '2024-01-15T14:30:00Z'
        endpoint:
          type: string
          example: '/v1/chat/completions'
        progress:
          type: number
          format: float64
          example: 75.0
          description: 'Completion progress (0.0 to 100)'
        model_id:
          type: string
          example: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo'
          description: 'Model used for processing requests'
        output_file_id:
          type: string
          example: 'file-output789xyz012ghi'
        error_file_id:
          type: string
          example: 'file-errors456def789jkl'
        error:
          type: string
        completed_at:
          type: string
          format: date-time
          example: '2024-01-15T15:45:30Z'
    BatchJobStatus:
      type: string
      enum:
        - VALIDATING
        - IN_PROGRESS
        - COMPLETED
        - FAILED
        - EXPIRED
        - CANCELLED
      example: 'IN_PROGRESS'
      description: 'Current status of the batch job'

    EvaluationTypedRequest:
      type: object
      required:
        - type
        - parameters
      properties:
        type:
          type: string
          enum: [classify, score, compare]
          description: The type of evaluation to perform
          example: 'classify'
        parameters:
          oneOf:
            - $ref: '#/components/schemas/EvaluationClassifyParameters'
            - $ref: '#/components/schemas/EvaluationScoreParameters'
            - $ref: '#/components/schemas/EvaluationCompareParameters'
          description: Type-specific parameters for the evaluation

    EvaluationClassifyParameters:
      type: object
      required:
        - judge
        - labels
        - pass_labels
        - input_data_file_path
      properties:
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        labels:
          type: array
          items:
            type: string
          minItems: 2
          description: List of possible classification labels
          example: ['yes', 'no']
        pass_labels:
          type: array
          items:
            type: string
          minItems: 1
          description: List of labels that are considered passing
          example: ['yes']
        model_to_evaluate:
          $ref: '#/components/schemas/EvaluationModelOrString'
        input_data_file_path:
          type: string
          description: Data file ID
          example: 'file-1234-aefd'

    EvaluationScoreParameters:
      type: object
      required:
        - judge
        - min_score
        - max_score
        - pass_threshold
        - input_data_file_path
      properties:
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        min_score:
          type: number
          format: float
          example: 0.0
          description: Minimum possible score
        max_score:
          type: number
          format: float
          example: 10.0
          description: Maximum possible score
        pass_threshold:
          type: number
          format: float
          example: 7.0
          description: Score threshold for passing
        model_to_evaluate:
          $ref: '#/components/schemas/EvaluationModelOrString'
        input_data_file_path:
          type: string
          example: 'file-01234567890123456789'
          description: Data file ID

    EvaluationCompareParameters:
      type: object
      required:
        - judge
        - input_data_file_path
      properties:
        judge:
          $ref: '#/components/schemas/EvaluationJudgeModelConfig'
        model_a:
          $ref: '#/components/schemas/EvaluationModelOrString'
        model_b:
          $ref: '#/components/schemas/EvaluationModelOrString'
        input_data_file_path:
          type: string
          description: Data file name

    EvaluationJudgeModelConfig:
      type: object
      required:
        - model_name
        - system_template
      properties:
        model_name:
          type: string
          description: Name of the judge model
          example: 'meta-llama/Llama-3-70B-Instruct-Turbo'
        system_template:
          type: string
          description: System prompt template for the judge
          example: 'Imagine you are a helpful assistant'

    EvaluationModelOrString:
      oneOf:
        - type: string
          description: Field name in the input data
        - $ref: '#/components/schemas/EvaluationModelRequest'

    EvaluationModelRequest:
      type: object
      required:
        - model_name
        - max_tokens
        - temperature
        - system_template
        - input_template
      properties:
        model_name:
          type: string
          description: Name of the model to evaluate
          example: 'meta-llama/Llama-3-70B-Instruct-Turbo'
        max_tokens:
          type: integer
          minimum: 1
          description: Maximum number of tokens to generate
          example: 512
        temperature:
          type: number
          format: float
          minimum: 0
          maximum: 2
          description: Sampling temperature
          example: 0.7
        system_template:
          type: string
          description: System prompt template
          example: 'Imagine you are helpful assistant'
        input_template:
          type: string
          description: Input prompt template
          example: 'Please classify {{prompt}} based on the labels below'

    EvaluationResponse:
      type: object
      properties:
        workflow_id:
          type: string
          description: The ID of the created evaluation job
          example: 'eval-1234-1244513'
        status:
          type: string
          enum: [pending]
          description: Initial status of the job

    EvaluationJob:
      type: object
      properties:
        workflow_id:
          type: string
          description: The evaluation job ID
          example: 'eval-1234aedf'
        type:
          type: string
          enum: [classify, score, compare]
          description: The type of evaluation
          example: classify
        owner_id:
          type: string
          description: ID of the job owner (admin only)
        status:
          type: string
          enum: [pending, queued, running, completed, error, user_error]
          description: Current status of the job
          example: completed
        status_updates:
          type: array
          items:
            $ref: '#/components/schemas/EvaluationJobStatusUpdate'
          description: History of status updates (admin only)
        parameters:
          type: object
          description: The parameters used for this evaluation
        created_at:
          type: string
          format: date-time
          description: When the job was created
          example: '2025-07-23T17:10:04.837888Z'
        updated_at:
          type: string
          format: date-time
          description: When the job was last updated
          example: '2025-07-23T17:10:04.837888Z'
        results:
          oneOf:
            - $ref: '#/components/schemas/EvaluationClassifyResults'
            - $ref: '#/components/schemas/EvaluationScoreResults'
            - $ref: '#/components/schemas/EvaluationCompareResults'
            - type: object
              properties:
                error:
                  type: string
          nullable: true
          description: Results of the evaluation (when completed)

    EvaluationJobStatusUpdate:
      type: object
      properties:
        status:
          type: string
          description: The status at this update
          example: pending
        message:
          type: string
          description: Additional message for this update
          example: Job is pending evaluation
        timestamp:
          type: string
          format: date-time
          description: When this update occurred
          example: '2025-07-23T17:10:04.837888Z'

    EvaluationClassifyResults:
      type: object
      properties:
        generation_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed generations.
          example: 0
        judge_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed judge generations
          example: 0
        invalid_label_count:
          type: number
          format: float
          nullable: true
          description: Number of invalid labels
          example: 0
        result_file_id:
          type: string
          description: Data File ID
          example: file-1234-aefd
        pass_percentage:
          type: number
          format: integer
          nullable: true
          description: Pecentage of pass labels.
          example: 10
        label_counts:
          type: string
          description: JSON string representing label counts
          example: '{"yes": 10, "no": 0}'

    EvaluationScoreResults:
      type: object
      properties:
        aggregated_scores:
          type: object
          description: Aggregated score statistics
        generation_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed generations.
          example: 0
        judge_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed judge generations
          example: 0
        invalid_score_count:
          type: number
          format: integer
          description: number of invalid scores generated from model
        failed_samples:
          type: number
          format: integer
          description: number of failed samples generated from model
        result_file_id:
          type: string
          description: Data File ID
          example: file-1234-aefd

    EvaluationCompareResults:
      type: object
      properties:
        num_samples:
          type: integer
          description: Total number of samples compared
        A_wins:
          type: integer
          description: Number of times model A won
        B_wins:
          type: integer
          description: Number of times model B won
        Ties:
          type: integer
          description: Number of ties
        generation_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed generations.
          example: 0
        judge_fail_count:
          type: number
          format: integer
          nullable: true
          description: Number of failed judge generations
          example: 0
        result_file_id:
          type: string
          description: Data File ID

    AudioFileBinary:
      type: string
      format: binary
      description: Audio file to transcribe

    AudioFileUrl:
      type: string
      format: uri
      description: Public HTTPS URL to audio file
